{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYgayWkAmema"
   },
   "source": [
    "## **Tic-Tac-Toe Classification by Multiple NN and Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUXTvyur5Pyk"
   },
   "source": [
    "##Read file and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aloxUTeQhJY8",
    "outputId": "bfb3d6e2-4339-438d-d55f-41facab45aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# for coloab only\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "root_dir = '/content/gdrive/My Drive/CE - ML &Deep Learning/Deep Learning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "0bbc5U8Yb0mC",
    "outputId": "018921d5-1429-47bb-dfdb-20835699d6ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')  # predefined plotting style\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# If you are on CoLab, copy tic-tac-toe.csv to the default dir '/content' before running this code.\n",
    "# Download tic-tac-toe.csv: https://drive.google.com/file/d/1WD4ibv0qqWpP4QoNpBAztx2fNylmZWyv/view?usp=sharing\n",
    "file_name = root_dir + 'tic-tac-toe.csv' \n",
    "# Import dataset\n",
    "dataset = pd.read_csv(file_name, names = '1 2 3 4 5 6 7 8 9 class'.split())\n",
    "X = dataset.iloc[:, 0:9].values\n",
    "y = dataset.iloc[:, 9:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "5jq_0LHMr9Mk",
    "outputId": "1e68dac9-ebe7-4a7b-c70d-13b1bb7d8ae2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5  6  7  8  9     class\n",
       "0    x  x  x  x  o  o  x  o  o  positive\n",
       "1    x  x  x  x  o  o  o  x  o  positive\n",
       "2    x  x  x  x  o  o  o  o  x  positive\n",
       "3    x  x  x  x  o  o  o  b  b  positive\n",
       "4    x  x  x  x  o  o  b  o  b  positive\n",
       "..  .. .. .. .. .. .. .. .. ..       ...\n",
       "953  o  x  x  x  o  o  o  x  x  negative\n",
       "954  o  x  o  x  x  o  x  o  x  negative\n",
       "955  o  x  o  x  o  x  x  o  x  negative\n",
       "956  o  x  o  o  x  x  x  o  x  negative\n",
       "957  o  o  x  x  x  o  o  x  x  negative\n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egzLGnfG5hGH"
   },
   "source": [
    "##LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m_lMJTECefDn",
    "outputId": "98d23d7d-1caa-4c63-a4e9-806724e4f5a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 1 1 2 1 1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables as numeric\n",
    "labelencoder_X = LabelEncoder()\n",
    "for i in range(9):\n",
    "    X[:, i] = labelencoder_X.fit_transform(X[:, i])\n",
    "print(X[0])\n",
    "\n",
    "# Encode target categorical variable\n",
    "labelencoder_y = LabelEncoder()\n",
    "y[:, 0] = labelencoder_y.fit_transform(y[:, 0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJxwEzXL5m_k"
   },
   "source": [
    "##Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bf7bbRlzx7y"
   },
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "# !!! DO NOT change test_size, random_state and stratify !!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Nc4nGHu-lHWP",
    "outputId": "b981f5bc-0726-4cac-d4f9-3bcd27c7ec7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (766, 9)\n",
      "class label 0 :  265\n",
      "class label 1 :  501\n",
      "\n",
      "======================================================\n",
      "\n",
      "Test shape:  (192, 9)\n",
      "class label 0 :  67\n",
      "class label 1 :  125\n"
     ]
    }
   ],
   "source": [
    "num_class_label = np.unique(np.array(y_train), return_counts=True)\n",
    "print('Train shape: ', X_train.shape)\n",
    "print('class label 0 : ', num_class_label[1][0])\n",
    "print('class label 1 : ', num_class_label[1][1])\n",
    "\n",
    "print('\\n======================================================\\n')\n",
    "\n",
    "num_class_label = np.unique(np.array(y_test), return_counts=True)\n",
    "print('Test shape: ', X_test.shape)\n",
    "print('class label 0 : ', num_class_label[1][0])\n",
    "print('class label 1 : ', num_class_label[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDLrKjD35qZG"
   },
   "source": [
    "##Init neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "qOuaY0FSz7JQ",
    "outputId": "b5a4022e-4c83-4876-a740-8e06fe63db1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network\n",
    "nnet = Sequential()\n",
    "\n",
    "# Add first hidden layer (and input layer)\n",
    "nnet.add(Dense(units=100, kernel_initializer='uniform', activation='relu', input_dim=9, use_bias=True))\n",
    "\n",
    "# Add second hidden layer\n",
    "nnet.add(Dense(units=100, kernel_initializer='uniform', activation='relu', use_bias=True))\n",
    "\n",
    "# Add output layer\n",
    "nnet.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid', use_bias=True))\n",
    "\n",
    "# Compile network\n",
    "from keras import optimizers\n",
    "optimizer = optimizers.SGD(lr=0.06, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "nnet.compile(optimizer=optimizer , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gttnJ61nysZw",
    "outputId": "7f46cc59-6aaf-4727-d7a3-793e9cf8d0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 899us/step - loss: 0.6509 - acc: 0.6501\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.6383 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.6366 - acc: 0.6645\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.6169 - acc: 0.6802\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.5976 - acc: 0.6971\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 417us/step - loss: 0.5632 - acc: 0.7454\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.5485 - acc: 0.7337\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.5161 - acc: 0.7598\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.4833 - acc: 0.7768\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.5005 - acc: 0.7676\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.4736 - acc: 0.7872\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.4460 - acc: 0.7833\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.4533 - acc: 0.7820\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.4201 - acc: 0.8120\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.3921 - acc: 0.8211\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.3683 - acc: 0.8446\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.3919 - acc: 0.8225\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.3382 - acc: 0.8486\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.3362 - acc: 0.8473\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.3133 - acc: 0.8681\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.3227 - acc: 0.8551\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.2852 - acc: 0.8812\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.2598 - acc: 0.8943\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.2707 - acc: 0.8890\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 0.2006 - acc: 0.9230\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.2964 - acc: 0.8903\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.2421 - acc: 0.9112\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.1606 - acc: 0.9360\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.2460 - acc: 0.9021\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.2180 - acc: 0.9086\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1572 - acc: 0.9426\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.1377 - acc: 0.9491\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.1045 - acc: 0.9569\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.2190 - acc: 0.9321\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 0.1911 - acc: 0.9282\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.1119 - acc: 0.9582\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.1597 - acc: 0.9269\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.2326 - acc: 0.9164\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.1526 - acc: 0.9504\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.1275 - acc: 0.9517\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.2090 - acc: 0.9321\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1051 - acc: 0.9687\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1124 - acc: 0.9608\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.0855 - acc: 0.9661\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.1581 - acc: 0.9491\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.0625 - acc: 0.9739\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.2093 - acc: 0.9308\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.1359 - acc: 0.9582\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1289 - acc: 0.9582\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1241 - acc: 0.9452\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.0983 - acc: 0.9634\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.1119 - acc: 0.9648\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.1099 - acc: 0.9674\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.1109 - acc: 0.9687\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.1789 - acc: 0.9491\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.0788 - acc: 0.9687\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.0932 - acc: 0.9595\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.1424 - acc: 0.9569\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.0467 - acc: 0.9883\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.0723 - acc: 0.9752\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.2103 - acc: 0.9347\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.0615 - acc: 0.9804\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1666 - acc: 0.9530\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1725 - acc: 0.9465\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.1032 - acc: 0.9621\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 438us/step - loss: 0.0377 - acc: 0.9830\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.0128 - acc: 0.9961\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 9.4826e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 6.5785e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 5.2005e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 4.3477e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 3.7397e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 3.3154e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 2.8993e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 2.6029e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 2.4065e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 2.1920e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 2.0230e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 358us/step - loss: 1.8757e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 1.7587e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 1.6472e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 1.5513e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 1.4733e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 1.4055e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 1.3254e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 1.2602e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 1.2058e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 1.1530e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 1.1130e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 1.0637e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 1.0209e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 9.8316e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 9.4793e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 9.1546e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 8.8448e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 8.5468e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 8.2782e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 8.0176e-05 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "history_dict = {}\n",
    "\n",
    "# TensorBoard Callback\n",
    "cb = TensorBoard()\n",
    "\n",
    "history_callback = nnet.fit(X_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zD6yH7Nt5670"
   },
   "source": [
    "## Training accuracy and Training Loss Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "pgO-JU6f0ASe",
    "outputId": "1349929a-e07f-4890-f257-590c650286b7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAF2CAYAAACYrmpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeVyU1f7A8c95GFxQFmdQETFFcM0V\ncc3EhWxTM2+Lt1tmttu1suXeNLtZ5s1fZZllVyvTbLuW3WxRW9BcUVMByw3ErUwUGFwQQZbn/P6Y\nwgjQQWYYGL7v18vXdZ7nzPN859zJ75zznEVprTVCCCGEqNEMTwcghBBCiMqThC6EEEJ4AUnoQggh\nhBeQhC6EEEJ4AUnoQgghhBeQhC6EEEJ4AUnoQgghhBeweDqAyjpy5IjLrhUcHExmZqbLrldbST26\nhtSja0g9uobUo2tUth5DQ0PLPSctdCGEEMILVEkL/Y033iAhIYHAwEBmzpxZ6rzWmgULFpCYmEjd\nunUZP348rVu3rorQhBBCCK9QJS30gQMHMnny5HLPJyYmcvToUWbPns0999zD22+/XRVhCSGEEF6j\nSlroHTt2JD09vdzzW7duZcCAASilaNu2LTk5ORw/fpxGjRpVRXhCCOESWmvYtxudnubpUFwut6E/\n5ulsT4dR8/hYMHrHVMmtqsWguKysLIKDg4tf22w2srKyykzocXFxxMXFATBjxowS76ssi8Xi0uvV\nVlKPriH16BpVUY+FaYfJW/M1eau/puiY6wbqVienPB1ADaUa+BN87V+KX7vz+1gtEnpFxMbGEhsb\nW/zalaMuZRSna0g9uobUo2u4sx51URH6rZfQ2zaAUtC+C+ram1GRHdxyP0+yWq1kZWV5OoyaxzBK\nfP/cOcq9WiR0q9Va4gPa7XasVqsHIxJCiAvTSxagt21AXf0X1MBrUVbv7VHxCQ5G+dTxdBjiPKrF\ntLXo6GjWrl2L1pqUlBT8/Pzk+bkQolozN6xEx32BGjIcY9TtXp3MRc1QJS30WbNmsWvXLrKzs7nv\nvvu46aabKCwsBGDo0KF0796dhIQEHnzwQerUqcP48eOrIiwhRA1nxq+E1N2oW+5DWaquw1Hv24N+\nfw506Iq6cVyV3VeI86mS/wIefvjh855XSnHXXXdVRShCCC+htUZ//iFkZYBvHdRf76ma+x63Y/7n\neWgUjHHP4ygfnyq5rxAXUi263IUQosL2JzuSeVg4etVXmOu+dfsttWlizp0BeXkYDzyJahjg9nsK\n4SxJ6EKIGklvXQ8WC8Zjz0HHbugP5qJTd5//PUcPU/TqVHTORc6nTtwI+5NRf70H1bzlxV1DCDeR\nhC6EqHG0aaK3boBOPVAN/DHueRyswZj/eR6dVf6UIL1lPexIQMevuoh7FmF+/iGEhKH6DqxE9EK4\nhyR0IWoJffRXdM5pT4fhGqm74YQdFd0fcCzeYfx9CuSfxZz3f44V28qgU3c5/nf9d+WWKY/esh7S\nfkGN+CvKkOfmovqRhC5ELaDPnMZ87hH0pws9HYpL6K3roE4dVNdexcdU6CWo625xPFvPKL30qi4q\ngn3J4B8IR352lHP2fkVF6C//C81bonpc5pLPIISrSUIXogbQWqN/3lfhVmXx+9fHwdlc9J4fXRyZ\nk/fPO4P+9RB693b0b1NWyyyXnoY+c/5eBG0WobfFQ+doVL36Jc6pTj0cZXaX8Tl/PQhnc1HX/Q3q\n1kNviHM+/s1r4NivGCP+ijLkn01RPVWLleKEEOenf1iLfnsmdO2FMfbBUqOrtWnCoVS4JKLUNCpt\nFqG/XwbKgIyj6KwMlLWx+2I9dQL27kQn70DvT4bMY/CHQWhq2GhHS/rP7ztux3zmQfAPxHjwX6jQ\nS8q+QfIOOHUC47fu9hKaNodGwejdSRBzVcnr/zZgTnXqAQeS0T+sQ990Z6kfBaXiKixEf/VfuKQ1\ndO97gU8vhOdIQheiJkjaDHXrw84EzGcfxrjrUVTbS4tbq3rZx/DrIdTQ61E33lHyvT9uhcxjqGtu\nRC//BJ2yA9VnUKVD0kVF8NNWdMZRsKej7elw9Fc4ethRoE5daN0O1bM/WJtAcBP0ptXo75aiB16N\nCiy5GqT+4kMoKoKCfMwZ/8S4/wlUh66l77t1PdStB517ljqnlEK174L+aQvaNEu2plN3gzUYZWsM\n/YeiN6xEb12P6n/F+T/nxlWQcRTj71NQSlW8ooSoIpLQhajmdFERemciKvoy1KBrMd98AfOlJ1Ex\nVzm60I8ehmYtHFO34j5H945BXdK6+P3mqq+gUTBq2Gj06uWQshNckdA/eQe98kvHi7r1wdYYmoai\n+g1Btb0UWkaWWr1Nt4zA/NcD6C8/Qt16bkVIfeRn9IaVqCHDULEjMGc/i/nqVNTf7se4fGjJukiI\nR3Xpiapbt+zAOnSFjavg8AG4JMLxPq3Re3eh2nR0lIloDyFh6PXfwXkSuj571vFjqVUb6FL6B4QQ\n1YlTCf306dM0bNjQ3bEIUWPpzGPQwB9V38/1F9+3G3JzUJ2jUS0jMJ56Bf3+fxzJuXlL1D3/QPXo\nC7m5mE/dj/neHIxJL6AMH/SRn2H3dtSoMShfX2hzKTp5R9mf4eRx+OVAyYPNWjhatH8u++sh9PfL\nUJfFOnoE/Bo61XpVTUJRA65Er/kaHTsCFRIGgPm/RVCvHuqam1D+ARj//D/HaPVFr1P04xZUh66o\ntp3gRBaczkb1vLz8e3Toggb07u2o3xI6WRlwwg6/JXSlFOryK9CfLECn/YJq1qLsOln6HtjTMe54\nSFrnotpzKqHff//9dO3alQEDBhAVFYWlCtdMFqKq6f3JmN9+hnHjOJStyYXLF+RjPveIo9U47vzL\nHF9UPD9tAx8f6NgNAFXPD+58BDX8r9A45Fy3coOGqJvvQr89E/39CtSQYehVX4HFF9Xf0cpVbS9F\nb/8BfSILFVRyR0NzznQ4kFLy5nXrO34c/GERFa015uK3oZ4f6oaxqAb+Ffo8athodPz3mP9bhM/4\nyeiUnbD9B9T1t6H8HWMDlF8DjAn/Qi99H71lLTppMxoc4wDq+0GnqPKvH2SDZi3Qu7fDlaMcMe91\nTFdTEee2NVV9BqH/twi9/rsy12PXyT85Nl8ZPAzVrnOFPqMQnuBUZn7ttddYv349S5YsYd68efTt\n25cBAwbQtm1bd8cnRJXRpon+9jP00vehqAjtH4T6230XfuOPWyAnG524EV0wHuXr2i0m9U9bIbJj\nida/Ugqalt4XWfUagN64Cv3Ze+j2ndEbv0f1jjmXKNt2crReU3ageg04d4/DB+BACurqG85NBcs/\nizn/Zcw50zGenHkucSducrT6/3rPRS19qgKCUFdej/7iQ3TqbsxPF0KQDTVkRMlyFgvqhrHov9wO\nmccciX/vDmjV9oJ1rNp3QW+IQxcUOA7s2w316kPYuR8mKiAIuvZGb/weff1tKIvvufrIO4O54FVo\n0gw1akyFP6MQnuDU/IugoCCGDRvGCy+8wNSpU6lfvz6zZs3ioYceYsmSJdjtdnfHKYRb6VPHMV99\nBv3pu9C1N0T1cyTGMzkXfK+5eY2jBZ2XCz9tc+5+Z3LQiZsw4z7HXPw2RXP+jbnwVbRZVLKcPcMx\n2K1LtFPXVUph/O1+MIswX5wM+WdRg4edK9CitSOx/anbXa+PA4sFNXQkKqK940+Hrhj3T4LjmZjz\nXnA8v84/i/nxfEdXf8zVTsVUZpxXXAeBjRybnOxPRl13S7nPxJVSqMYhGJcNwRj7EMbAC99XdegK\n+WeL55rrvbsgon2pBWGMmCsh+yTmC5PQP+87Vx+fLICsTIw7HkbVrXfRn1OIqlThCZU5OTnk5ORw\n9uxZrFYrR48e5bHHHuOLL75wR3xCuJXWGp2wEfPZh2HvTtSt4zHu+yfGNTfA2Tx0/PnnKuuc0/DT\nVtSAq8A/0DEC25n7fjAX841/oxfPR6/7Fn496Bh1vWlNyXI/bQVAdXYuoQOoxiGo4aMdU8XaXlpi\ngJzy8XE8R085l9B1Qb6jJd+9b6kWt4poj7r1Adi9Hb1kAfrbpY5nyjffValdxlS9+o5HBqdOQOgl\nqH6DL/paZWrXCZSB3rMdMycbjvyMiuxQqpjq2B1116OQeQzzuUcx//sW5pb16LXfOH7clPEeIaor\np7rcjxw5wtq1a1m/fj0+Pj7ExMQwY8YMGjd2DJY5duwY//jHPxgxYsQFriRE9aEzjmJ+9Cb8tBXC\nWmE8/AwqrJXjZMtIiOyAXrUMPXhYuUt96oR4KCx0JCSzyNF9ezbvvK06XVCA/vEHVK8BqNH3QEN/\n0Brz34+hP/8A3bN/cZey3rENgpvCb4PHnKWuGOmYqta39Gh21fZS9E9b0aeOowIaoRM3wZnT5U7f\nMi4bgnn4ADruC/CxQFTfMqeTVZTqf4VjKdXeMS5fSlX5NYRWkejd2ynYswO0RkV2LLOs0TsG3bkH\n+rP3HWMOVn7p+JFRxlx5Iaozp1roTz75JKdOnWLChAm8+uqrjBo1qjiZAzRt2pQrr7zSbUEK4Uq6\nqAhz+SeYU/8OKTtQN47DmPLKuWT+GzV4OGQchZ8Syr/W5jWOxUxaRjpGXuefRf+49fwB7PkR8nJR\nfQai/AMcXcqGgXHDWMjKQK9a5rh2/lnHs+rOPSo8wlpZLBi3PVBmElNtOzn+krLTcZ/134GtCbTv\nUv71brjDMR3Mx8C44Y5yy1UoRh8fjNF3o8LdMxZHte8CB1I4m7gRDAPOcx/l1xDjb/dhTHoJ1fNy\njLsfc/lYCCHczakW+ptvvomvr+95y9xyi/yaFTWDXr0C/dl7ENXX0XVczqppqnsfdJANc9VX+HQt\nPQdZZ2U6fhAMG41SCt2mIwQ2cqwz3rOMVcx+f1/SJse87T8lUNW+C3Tq4Vj8pf8V5P+S6ngGXsYC\nKpVySYRj6dOUHY6eiN3bUSNuOe+SpsrHB+PBpyH7JKqRzbXxuInq0BW9Ygm5333pWEHPiWfhKrwN\n6p7HqyA6IVzPqRb6Bx98QEpKyeksycnJLFq0yC1BCeFOett6CGuFz/2TzrsEqrJYUAOvhl2J6LRf\nSl9nyzpHV26fGEd5w8exccdP29B5Z8q+t2mikzajOkWV2QI0/jIGcnPQKz7h7LZ4qFPH8TzYhZTF\n4nickLwDHb8SlEL1G+LU+2pKMgcgsgP41nH8KJJn4aIWcCqhr1+/nvDw8BLHwsPDWbdunVuCEqIi\nzPiVjtXQnKBPnYDU3ajufZwqrwZcCRbf4m7wEtfavBrC26KanJs+pnr2h4J8dNIPZV/wQIpjIFg5\n91dh4Y750Su/4mz8amjXBVWnnBXRKkG17QRHfkav+Rou7V7m4jE1nfKt40jqUO7zcyG8idOj3Mva\n5ck0TZcGI0RF6bxc9H/fRv/vPXRB/oXLb//B0aru5mRC9w88N7f7D3uJ6yM/wy8HSszlBqB1e8fm\nIOWMdteJG8HHct5R6+q6vwFgHs+s0Oj2iih+jp59EuMCa5nXZKpTD7BYoI200IX3cyqht2vXjo8/\n/rg4qWutWbJkCe3atXNrcEJciN60GnJz4GyuY7DZhconbXYMAGsRfsGyv1NDhjkWWZl8D+YH/0Hv\n24PevBaUUWoJUmUYqOjLYEdCqW1AtdaOEeXtOqP8GpR/P1tjVOwIMHycnn9eYa0iHd35DQPgD3uK\nexs1eBi2We+jAhpduLAQNZxTg+LuuOMOnn/+edatW0fjxo3JyMjA39+fJ554wt3xCVEurbVjmlGL\ncMe2oImbztui1Xm5sCsJNfDqCo0aV5dEYDw6Hb32G3T8SvTqFY4THbuX2jEMQPW8HP3d5+jEzajL\n/vBsOu0XSE9zTCm70D1H3or1mlGcqF+xZVWdpSy+qGtugoCgEiukeRtlsWAJCYHMTE+HIoTbOZXQ\ng4ODefHFF0lOTsZutxMcHEzbtm0xzjMqVgi3273dMY/5jodhxzbHet+33l/+nOadCVBY4HR3+x+p\ndp1Q7Tqhc8+gE+LRiZswYstZd6FVG2gcgl62GN2hS/HAO524yXGtbhduESsfHywtwt2aiIxrb3Lb\ntYUQVc/pjGwYBh06dKB///60b99ekrlwC6015v/eRR/Ye8Gy5qqvwD/Q0e3dvQ9knyxe6rPMaydu\nciziUokRz6q+H8Zlsfj8fYpjmllZZZTCuPMROH0K88XJjn3Cf79/eFvH5iFCCOFiTrXQc3Nz+fTT\nT9m1axfZ2dklBsi9/vrrbgtO1EKHD6JXfIpO+xWfByaXW0ynp8GPW1DX3uTYFrRTD7SPxdHtXsaI\nZl1YiP5xK6p7n0otWeosFdEeY+KzmLOexnxxMsa4h+FQKmrU7W6/txCidnKqmT1//nxSUlIYMWIE\nJ0+e5NZbbyUwMFBWhxMu93u3NDsTHM+8yyv3/XIwDFTMVYCj5UyHLujETWXOyCDlJ8ee4k5OV3MF\nFd4W45HnIPcM5swpjmPde1fZ/YUQtYtTCT0pKYnHHnuMPn36YBgGffr0YeLEiaxf79xGFEI4Sydu\nggb+jrnc5excpvNy0RviUD0uK9F9rbr1cSzVeuTnMq67GerULd5TvKqolhEYj00HvwaOHcoquCa7\nEEI4y6mEbpomDRs2BKBevXqcOXOmeKc1IVxFZxyFwwdQV40C/0BIiC+73KbvHa3tP24LCqhuvUGp\nc63838v/tjobl3Z3yyItF6JahGM88zrGQ1Or/N5CiNrDqWfoLVu2ZNeuXXTq1Il27drxzjvvUK9e\nPUJCQtwdn6hF9PbNAKiovpBxDL15NTr/bIkkrIuK0N994ViDvHXJdRBUYCNo3c6R0IfdfO7EoX1w\nwo7qPqZKPkdZZB60EMLdnGqh33vvvdhsjq7NO+64A6UUJ06c4IEHHnD6RklJSTz00ENMmDCBpUuX\nljqfkZHBs88+y2OPPcbUqVOx2+1OX1t4B5242dEt3SQU1aMfnM2DnYkly2xeDelHMK65scy55Kpb\nb/h5H9qe4SifshNzwSzH6mzuWqRFCCGqgQu20E3TZP369Vx33XUABAUFVSiR/36N+fPnM2XKFGw2\nG5MmTSI6OpqwsHPPE9977z0GDBjAwIED2bFjBx9++CETJkyo4McRNZXOPgl7d6GuvdFxoG0naOCP\nTogvHsimCwvRXy2GS1qXvxZ6tz7oT99Fr/8WnZXp2HzE2hjjgSdRDdyzSIsQQlQHF2yhG4bB8uXL\nsVic6p0vU2pqKiEhITRt2hSLxUK/fv3YsmVLiTKHDx+mUyfH+tKXXnopW7deYE9p4VX0j1tAm8WL\nviiLBdWtF3r7FnRBgaPMxlWQcRRjxN/KXelNhTSHZi3QXy1Gb16NuvovGM/OQXXuUWWfRQghPMGp\nLvfLL7+clStXXvRNsrKyirvsAWw2G1lZWSXKtGzZkh9+cOxQ9cMPP5Cbm0t2dvZF31PULDpxE1iD\nHa3v36gelznWad+zHV1Y4Gidh7eFC3Sdq6v+At36YPzrVYxRtzu1D7YQQtR0TjW7Dx48yLfffsvn\nn39OcHBwiXNPP/20SwK57bbbeOedd1i9ejUdOnTAarWWuRpdXFwccXFxAMyYMaNUPJVhsVhcer3a\nqqL1qPNySd+dRP0rRhDQ+Nw2nrr/YDLenkmdnQn4nj1DdlYGQX+fRN3GF9jqc8RNjj81nHwfXUPq\n0TWkHl3DnfXoVEKPiYkhJibmom9itVpLDHKz2+1YrdZSZR577DEA8vLy2Lx5Mw0alN6RKjY2ltjY\n2OLXmS5c6zo4ONil16utzlePOuc0evnHjk1U2nVGKYVOiIf8fM6271b6fV16krdpDXnbNkJkB06F\nRaBqyf9H8n10DalH15B6dI3K1mNoaGi555xK6IMHD77omwNERESQlpZGeno6VquV+Ph4HnzwwRJl\nTp06RcOGDTEMg88++4xBgwZV6p6i+tFFRZhvvgC7ktDfLoXIDhjDRju62/0aQptLS71HRfVzbJEK\nGHdOrNAuaUIIUZs4ldDXrFlT7jlnWu4+Pj6MGzeO6dOnY5omgwYNokWLFixevJiIiAiio6PZtWsX\nH374IUopOnTowJ133un8pxA1gl6y0LF96S33OV6vWII5y/HIRvUdVPYa65d2h3r1oWVkuZuhCCGE\ncDKh/3lA3IkTJ8jIyKBt27ZOd8VHRUURFRVV4tjNN59b/KNPnz706VN162yLqmXGr0THfY4aPAxj\n0DUA6P5XoDeuRG9YiYq5usz3qTp1MR7/NwRayzwvhBDCwamE/uyzz5Y6FhcXx7Fjx1wekPA+en8y\n+r03HM/MbxxXfFz5+qIGXAUDrjrv+9UlEe4OUQgharyL3tR88ODBlZrKJmoHfeoE5hvPQ5AV475/\noiqxnoEQQojyXdS/rvn5+axbt4769eu7Oh7hZfT3y+DUcYynZqEaBng6HCGE8FpOJfQ/Puv+XVBQ\nEPfee6/LAxLeQxcWotd9B516oFqEezocIYTwak4l9FdffbXE63r16hEUFOSWgIQX2f4DnMzCiKnY\n2v9CCCEqzqmEXq9ePXx9fUss9JKTk0NBQYEkdlEuc80KsDaGzlEXLiyEEKJSnBoU93//93+lVrbJ\nyMjgxRdfdEtQoubQ6Ucwv1+O1rrk8WNHYPd21IArUUYZ88uFEEK4lFMt9CNHjtCyZcsSx1q1asXh\nw4fdEpSoGbTWmAtmQ+ouyMlGDTs31kKv/Rp8fFCXxZ7nCkIIIVzFqRZ6QEBAqTnnx44do2HDhm4J\nStQQu5McybxxCPrzD9BJmwDQ+WfRG1ZCt96oIFkQRgghqoJTCT0mJoaZM2eSlJTEkSNHSExM5OWX\nX5b11msxrTXm0g/A2hhjyivQMhLz7VfQvx4iL34V5GRjlLP6mxBCCNdzqst91KhR+Pj4MH/+fOx2\nO8HBwQwePJgRI0a4Oz5RXe3YBgdSULc9gPJrgPHAk5jTH8GcM50z/oHQtDnI2utCCFFlnErohmFw\n/fXXc/3117s7HlEDaK0xP/8Qgpui+g0BQDWyYdw/CfOlyRRmHEXddKfsjCaEEFXIqS73L774gn37\n9pU4lpqaypdffumWoEQ1t30zHEpFDRtdYilXFdEedfuDWCI7oPpVbstdIYQQFeNUQl+2bBnNmzcv\ncax58+Z89dVXbglKVB9aa7RpnnttmpiffwRNmqH6DCxV3ugzENuL81EN/KswSiGEEE51uRcUFGD5\n06Yavr6+5OfnuyUoUX3oBa+if1gDjYLB1sSxN/nhA6g7J5a9f7kQQgiPcKqFHh4eTlxcXIljK1eu\npFWrVu6ISVQhnbARffhA2edO2NGbV0NEB1TrdlBYAIf2QWRHVK8BVRuoEEKI83KqhX777bczbdo0\n1q5dS9OmTTl69Ch2u50pU6a4Oz7hRjorA3Pe/0HoJRj/erXUIDa9/jswTYwxf0c1DfVQlEIIIZzh\nVEK/5JJLePXVV9m6dSt2u53u3bsTHR2Nn5+fu+MTbqRXfgmmCYcPwo9boWvPc+eKitBrv4WO3SSZ\nCyFEDeD0fuh+fn4MGCDdrN5Cn8lBr/0G1eMy9MG9mMs/xugSfa6V/tNWOJ6JMfouzwYqhBDCKU4l\ndNM0+e6779i1axfZ2dklNuJ4+umn3RaccB+97lvIy0VdfQPsT0Z/OBf2/AgdugJgrvkagqzQpZeH\nIxVCCOEMpwbFvfvuu6xYsYLIyEj27t1LVFQUWVlZtG/f3t3xCTfQhQXouC+gfRdUywhU/1gIbIS5\n/BPH+YyjsDMB1X9oiXnmQgghqi+nEvqmTZuYPHkyw4cPxzAMhg8fzuOPP87u3bvdHZ9wA711PZyw\nYwx1rPynfOugrhgJe35E79vjaL2jUJdf4dlAhRBCOM2phJ6fn0/jxo0BqFu3Lvn5+YSFhXHgQNnT\nnUT1pbVGf7MUmrWATlHFx1XMVdDAH/Or/zpGt3ftibI29mCkQgghKsKp/tTQ0FD27dtHZGQkrVu3\nZsmSJfj5+dGoUSN3xydcbfd2x8IwYx8sMU1N1auPGjIc/cWHABgxV3kqQiGEEBfBqRb67bffjmE4\nio4ZM4aUlBQ2btzI3Xff7dbghGtprTG//hQCG6F6xZQ6rwYPc6wEF9wUOnb3QIRCCCEullMt9LZt\n2xb/PTQ0lKlTp7orHuEmuqAAveg12L0ddeM4lK9vqTKqQUOM+5+AuvVRhlO/9YQQQlQTMoS5FtCn\nT2H+53lI2YkaeSvqiuvKLaukZS6EEDWSJHQvp9OPYL76LGRloO5+DEPWYBdCCK8kCd2L6TOnMWf8\nE7SJ8eg0VGRHT4ckhBDCTeRBqRfT2+Ih+yTGA1MkmQshhJdzqoW+Zs2aMo/7+vpitVqJjIwstV/6\nnyUlJbFgwQJM02TIkCGMHDmyxPnMzEzmzJlDTk4Opmlyyy23EBUVVc7VhDP05jXQtDlEyIp+Qgjh\n7ZxK6HFxcezbtw9/f3+sVitZWVlkZ2cTHh5Oeno6FouFxx9/nNatW5f5ftM0mT9/PlOmTMFmszFp\n0iSio6MJCwsrLvPpp5/St29fhg4dyuHDh3n++ecloVeCzsqElB2o4X8ttS2qEEII7+NUQg8PD6d3\n794MGzas+NiyZctIT09n2rRpLFmyhAULFjBt2rQy35+amkpISAhNmzYFoF+/fmzZsqVEQldKcebM\nGQDOnDkji9ZUkt6yFrRG9ZZBcEIIURs4ldDXrVvH/PnzSxy7+uqrufPOO7njjju4/vrrWb58ebnv\nz8rKwmazFb+22Wzs3bu3RJkbb7yR5557jq+//pqzZ8/y1FNPlXmtuLg44uLiAJgxYwbBwcHOfASn\nWCwWl17Pk+zbNkCbjtg6dqnye3tTPXqS1KNrSD26htSja7izHp1K6AEBASQmJtKjR4/iY0lJSQQE\nBABQUFBQvJLcxdqwYQMDBw5k+PDhpKSk8NprrzFz5sxS142NjSU2Nrb4dWZmZqXu+0fBwcEuvZ6n\n6CM/Yx7Yixp9t0c+j7fUo6dJPbqG1KNrSD26RmXrMTQ0tNxzTiX0sWPHMmvWLFq1aoXNZsNut3Pw\n4EEefvhhAFJSUhg6dGi577dardjt9uLXdrsdq9VaosyqVauYPHky4FiZrqCggOzsbAIDA50JUfyB\n3rwGDAPVs7+nQxFCCFFFnK/v9wQAACAASURBVGpWd+/endmzZzNw4EDCwsKIiYlh9uzZdO/uWFWs\nW7dujB49utz3R0REkJaWRnp6OoWFhcTHxxMdHV2iTHBwMDt27ADg8OHDFBQUFPcACOdprR0JvUNX\nVICMQxBCiNrC6YVlAgMDGTRo0EXdxMfHh3HjxjF9+nRM02TQoEG0aNGCxYsXExERQXR0NGPGjGHe\nvHksW7YMgPHjx8vo7D/RZ/NgRwJ06ILya1h2oX17wJ6OGnFL1QYnhBDCo5xK6BkZGSxevJiDBw+S\nl5dX4tzrr7/u1I2ioqJKTUO7+eabi/8eFhZW7ih54aCXLESvXg4WX1S33qi+g6Bjd9Qf1gDQm9dA\nnTqoqD4ejFQIIURVcyqhz549G5vNxujRo6lbt667YxJl0MeOoNd9g+pxGQRZ0ZvXoLeuhwb+ENIc\nZWsCtiboretQXXuj6vl5OmQhhBBVyKmE/vPPP/PMM89UeiS7uHjmZ4scLfNb7kEFNELfMBZ2JKCT\nNqMzj6H3J8O2DVBUhOofe8HrCSGE8C5OJfT27dtz6NAhwsPD3R1PraZPHQd7Biq8bcnj+5NhWzxq\n+OjigW7K4gvdeqO69T5XziyCvNzyn68LIYTwWk4l9JCQEKZPn06fPn0ICgoqce6GG25wS2C1jS4q\nwpw9DQ6lokbdjrpqFEoptNaYny4E/0DU0JHnvYYyfECSuRBC1EpOJfTTp0/TtWtXcnNzyc3NLT4u\no9BdR3+/DA6lQqs26P+9CxlpcMt9sDMRUnaibrlPnosLIYQol1MJfcKECe6Oo1bTWRnopR9Apx4Y\nE55Cf/4hevnHaHs6HLdDk1DU5eUv3COEEEKUm9Dtdnvx+uvnW6ZO1vatPPOjN0EXYdxyL8owUNff\nitkkBP3eHCgqwrjvnyWmpgkhhBB/Vm6WmDhxIosWLQLggQceKPcCixcvdn1UtYhO3ARJm1E3jEU1\nDik+blwWi24cgt67C6L6eTBCIYQQNUG5CX3hwoXFf//oo4+qIpZaR+eewfxwHoSFo4aMKHVete2E\natvJA5EJIYSoacpN6H+ccy7zz91Df/VfOJmFMX6SdKkLIYSolCpb+lWUpPNy0Wu/QfWOKTXvXAgh\nhKgoWfrVQ/QPaxyLwAy8xtOhCCGE8AKy9KsHaK3Rq1dAWDi0bufpcIQQQngBpzL070u/Chc5kAK/\nHEDFXCWL8wghhHAJWfrVjfTRX6GhP6phQMnja76GuvVRfWI8FJkQQghvI0u/uonWGvOlyVDPD+Of\n/4fydyR1nZON3rIO1W+wLOUqhBDCZWTpV3fJSIOTx+HkcczXnsV4ZBqqXn30xlVQkI+KudrTEQoh\nhPAi5T5Dt9vtxX/PzMws948om96XDIAaeSscTMWcOwNdWODobm/dDtVCtqIVQgjhOrL0q7vsT4Z6\n9VFX/wUCgtCLXsd8YRIc/RV1x0Oejk4IIYSXkaVf3UTv3wPhbVGGD+ryoZinTqCXvg9+DVHR/T0d\nnhBCCC8jS7+6gT6bB4cPoq46NwNAXXMj+NaBwEaoOrI4jxBCCNdyalCcaZp899137Nq1i+zsbLTW\nxeeefvpptwVXYx1KBdNERZxbNEYphRo60oNBCSGE8GZONb3fffddVqxYQWRkJHv37iUqKoqsrCza\nt2/v7vhqpN8HxBEuq8AJIYSoGk4l9E2bNjF58mSGDx+OYRgMHz6cxx9/nN27d7s7vhpJ70+GJs2K\n554LIYQQ7uZUQs/Pz6dx48YA1K1bl/z8fMLCwjhw4IBbg6uJtNZwIBnVWnovhBBCVB2nnqGHhoay\nb98+IiMjad26NUuWLMHPz49GjRq5O76ax57uWFBGNl0RQghRhZxqod9+++3FI93HjBlDSkoKGzdu\n5O6773ZrcDWR3v/bgjIRktCFEEJUnQu20E3TJC0tjX79+gGO1vrUqVPdHVfNtT8Z6tSB5q08HYkQ\nQoha5IItdMMweOedd/D19a2KeGo8vT8ZWrVB+fh4OhQhhBC1iFNd7lFRUSQkJLg7lhpPF+TDz/tl\nQJwQQogq59SgOK01M2fOpH379thsthLnxo8f79SNkpKSWLBgAaZpMmTIEEaOLLnIysKFC9m5cyfg\nGFV/8uTJEsvP1giH9kFRIUoGxAkhhKhiTiX0kJAQhg8fftE3MU2T+fPnM2XKFGw2G5MmTSI6Opqw\nsLDiMmPHji3++4oVK2rklLjfB8TJCHchhBBV7bwJff369fTv35/Ro0dX6iapqamEhITQtGlTAPr1\n68eWLVtKJPQ/2rBhAzfddFOl7ukJev8esDVBBcp0PiGEEFXrvAn9rbfeon//yu8MlpWVVaKr3maz\nsXfv3jLLZmRkkJ6eTqdOnco8HxcXR1xcHAAzZswgODi40vH9zmKxXPT1tGmSeXAvvh26EuTCmGqi\nytSjOEfq0TWkHl1D6tE13FmP503of9yEpaps2LCBPn36lLvDW2xsLLGxscWvMzMzXXbv4ODgi76e\nuXoF2p5BfsfuLo2pJqpMPYpzpB5dQ+rRNaQeXaOy9RgaGlruufMmdNM02bFjx3kvXl5L+o+sVit2\nu734td1ux2q1llk2Pj6eO++884LXrE70iSz0/xZB+y6y17kQQgiPOG9CLygoYO7cueW21JVSvP76\n6xe8SUREBGlpaaSnp2O1WomPj+fBBx8sVe7XX38lJyeHtm3bOhl+9aAXvw0F+Ri3jkcp5elwhBBC\n1ELnTej16tVzKmFfiI+PD+PGjWP69OmYpsmgQYNo0aIFixcvJiIigujoaMDR3d6vX78alRT1T1vR\nW9ejrvsbqmn5XSFCCCGEOzk1bc0VoqKiiIqKKnHs5ptvLvG6po1s12fzMD+YC81aoK4a5elwhBBC\n1GLnXSnOE4PiahL9xUdgT3d0tVtkaVwhhBCec96EvmjRoqqKo8bRB/ei4z5HXT4U1fZST4cjhBCi\nlnNqLXdRki7Ix3xnFgQ0Qv1lrKfDEUIIISShXwy99ANI+wXj9gmoBg09HY4QQgghCb2i9N5d6O+W\nogZcheoUdeE3CCGEEFVAEnoF6LxczAWzHOu13zjW0+EIIYQQxSShV4D+9F3IPIYx9iFUPT9PhyOE\nEEIUk4TuJHPtN+jVy1FDRqDaXXi5WyGEEKIqVdnCMjWZuXo5+oO50CkKNeo2T4cjhBBClCIJ/QLM\nlV+h//smdOmJcd8TKF9ZQEYIIUT1Iwn9PMzvPkd/PB+69cG493FZDU4IIUS1JQn9T/SpE+gt69Ab\nv4dDqdCjH8Zdj6EsUlVCCCGqL8lSv9Gpuzn+5peYCRuhqAhaRqJG34MaeDXKx8fT4QkhhBDnJQn9\nd6dPUrhvDyr2OlTfQajmLT0dkRBCCOE0Sei/69KT4EFXYz9+3NORCCGEEBUm89B/owwf6VoXQghR\nY0lCF0IIIbyAJHQhhBDCC0hCF0IIIbyAJHQhhBDCCyittfZ0EEIIIYSoHGmh/8ETTzzh6RC8gtSj\na0g9uobUo2tIPbqGO+tREroQQgjhBSShCyGEEF7AZ+rUqVM9HUR10rp1a0+H4BWkHl1D6tE1pB5d\nQ+rRNdxVjzIoTgghhPAC0uUuhBBCeAHZnOU3SUlJLFiwANM0GTJkCCNHjvR0SDVCZmYmc+bM4cSJ\nEyiliI2N5ZprruH06dO88sorZGRk0LhxYyZOnEjDhg09HW61Z5omTzzxBFarlSeeeIL09HRmzZpF\ndnY2rVu3ZsKECVgs8p/t+eTk5DB37lx++eUXlFLcf//9hIaGyvexgr766itWrVqFUooWLVowfvx4\nTpw4Id/HC3jjjTdISEggMDCQmTNnApT776HWmgULFpCYmEjdunUZP358pbrjpYWO4x/R+fPnM3ny\nZF555RU2bNjA4cOHPR1WjeDj48Ntt93GK6+8wvTp0/nmm284fPgwS5cupXPnzsyePZvOnTuzdOlS\nT4daIyxfvpzmzZsXv37//fe59tpree2112jQoAGrVq3yYHQ1w4IFC+jWrRuzZs3ixRdfpHnz5vJ9\nrKCsrCxWrFjBjBkzmDlzJqZpEh8fL99HJwwcOJDJkyeXOFbe9y8xMZGjR48ye/Zs7rnnHt5+++1K\n3VsSOpCamkpISAhNmzbFYrHQr18/tmzZ4umwaoRGjRoV/6KsX78+zZs3Jysriy1bthATEwNATEyM\n1KcT7HY7CQkJDBkyBACtNTt37qRPnz6A4x8KqcfzO3PmDLt372bw4MEAWCwWGjRoIN/Hi2CaJvn5\n+RQVFZGfn09QUJB8H53QsWPHUr0/5X3/tm7dyoABA1BK0bZtW3JycjheiS28pa8Ex69Rm81W/Npm\ns7F3714PRlQzpaenc+DAASIjIzl58iSNGjUCICgoiJMnT3o4uupv4cKF3HrrreTm5gKQnZ2Nn58f\nPr9t62u1WsnKyvJkiNVeeno6AQEBvPHGGxw6dIjWrVszduxY+T5WkNVqZfjw4dx///3UqVOHrl27\n0rp1a/k+XqTyvn9ZWVkEBwcXl7PZbGRlZRWXrShpoQuXyMvLY+bMmYwdOxY/P78S55RSKKU8FFnN\nsG3bNgIDA2VaUCUVFRVx4MABhg4dygsvvEDdunVLda/L9/HCTp8+zZYtW5gzZw7z5s0jLy+PpKQk\nT4flFdz5/ZMWOo5fmna7vfi13W7HarV6MKKapbCwkJkzZ3L55ZfTu3dvAAIDAzl+/DiNGjXi+PHj\nBAQEeDjK6i05OZmtW7eSmJhIfn4+ubm5LFy4kDNnzlBUVISPjw9ZWVnyvbwAm82GzWajTZs2APTp\n04elS5fK97GCfvrpJ5o0aVJcT7179yY5OVm+jxepvO+f1WolMzOzuFxlc4+00IGIiAjS0tJIT0+n\nsLCQ+Ph4oqOjPR1WjaC1Zu7cuTRv3pxhw4YVH4+OjmbNmjUArFmzhp49e3oqxBrhlltuYe7cucyZ\nM4eHH36YTp068eCDD3LppZeyadMmAFavXi3fywsICgrCZrNx5MgRwJGYwsLC5PtYQcHBwezdu5ez\nZ8+itS6uR/k+Xpzyvn/R0dGsXbsWrTUpKSn4+flddHc7yMIyxRISEnj33XcxTZNBgwYxatQoT4dU\nI+zZs4d//etfXHLJJcXdSH/9619p06YNr7zyCpmZmTJNqIJ27tzJl19+yRNPPMGxY8eYNWsWp0+f\nJjw8nAkTJuDr6+vpEKu1gwcPMnfuXAoLC2nSpAnjx49Hay3fxwr6+OOPiY+Px8fHh1atWnHfffeR\nlZUl38cLmDVrFrt27SI7O5vAwEBuuukmevbsWeb3T2vN/Pnz2b59O3Xq1GH8+PFERERc9L0loQsh\nhBBeQLrchRBCCC8gCV0IIYTwApLQhRBCCC8gCV0IIYTwApLQhRBCCC8gCV0IIYTwApLQhRBCCC8g\nCV0IIYTwApLQhRBCCC8gCV0IIYTwApLQhRBCCC8gCV0IIYTwApLQhRBCCC8gCV0IIYTwApLQhRBC\nCC9g8XQAlXXkyBGXXSs4OJjMzEyXXa+2knp0DalH15B6dA2pR9eobD2GhoaWe05a6EIIIYQXkIQu\nhBBCeAFJ6EIIIYQXkIT+G33yOKf/+zY6/6ynQxFCCCEqTBL6b3TiJnIWv4P5zEPo5J88HY4QQghR\nIZLQf2MMvJqgqa+CNjFfehLz3dfQOac9HZYQQgjhlBo/bc2V6nbtifH0a+gvP0J/txSdsBGahYF/\nIMo/EBoFowZdg2oY4OlQhRBCiBIkof+JqlsXdcNYdK8B6LjP0SeyIOMoen8yZJ9EJ2zEeGQayl+S\nuhBCiOpDEno51CWtUeMmljimdyZizpmO+fIUjEeek6QuhBCi2pBn6BWgLu2O8fcn4dgRzJlPorNP\nejokIYQQApCEXmGqY3eMCU9BRhrmzCnoUyc8HZIQQghRdV3uSUlJLFiwANM0GTJkCCNHjixVJj4+\nnk8++QSlFC1btuShhx6qqvAqRHXoivH3pzBfn4b50pOOZ+pBVk+HJYQQoharkoRumibz589nypQp\n2Gw2Jk2aRHR0NGFhYcVl0tLSWLp0KdOmTaNhw4acPFm9u7NVh64YD07FfO1ZR1J/9DlUI5unwxJC\nCFFLVUmXe2pqKiEhITRt2hSLxUK/fv3YsmVLiTIrV67kyiuvpGHDhgAEBgZWRWiVotp1wnh4KpzM\nwnxxEtqe7umQhBBC1FJVktCzsrKw2c61Xm02G1lZWSXKHDlyhLS0NJ566imefPJJkpKSqiK0SlOR\nHTEemQanszFfnIzOPObpkIQQQtRC1WbammmapKWl8fTTT5OVlcXTTz/NSy+9RIMGDUqUi4uLIy4u\nDoAZM2YQHBzsshgsFsvFXS84mIJpr3P8XxOwfDiXoGdmo5RyWVw1zUXXoyhB6tE1pB5dQ+rRNdxZ\nj1WS0K1WK3a7vfi13W7HarWWKtOmTRssFgtNmjShWbNmpKWlERkZWaJcbGwssbGxxa8rs1H8n1Vq\n4/lAG1x3C/kfvUlm3DJU9z4ui6umqVQ9imJSj64h9egaUo+uUdl6DA0NLfdclXS5R0REkJaWRnp6\nOoWFhcTHxxMdHV2iTK9evdi5cycAp06dIi0tjaZNm1ZFeC6jYq6GZi0wP3kHXVDg6XCEEELUIlXS\nQvfx8WHcuHFMnz4d0zQZNGgQLVq0YPHixURERBAdHU3Xrl3Zvn07EydOxDAMbr31Vvz9/asiPJdR\nPj4YN9+FOetp9MovUFf9xdMhCSGEqCWU1lp7OojKOHLkiMuu5aoupaLXpkHKDozpc1EBjVwQWc0i\nXXOuIfXoGlKPriH16Bo1vsu9tjFuHAcFBejP3vd0KEIIIWoJSehuoEKaowZfi94Qhz60z9PhCCGE\nqAUkobuJGnYzNAzAfHUqesc2T4cjhBDCy0lCdxPl1xDj8echsBHmq89gLlmALiz0dFhCCCG8lCR0\nN1LNwjAmvYiKuQr9zWeYLzwhy8MKIYRwC0nobqbq1MW4dTzGvf+Ao4cxX30GXShz1IUQQriWJPQq\noqL7Y9z5KKT9go77wtPhCCGE8DKS0KuQ6toTuvVGf/lftD3D0+EIIYTwIpLQq5gx+m5AYy5+y9Oh\nCCGE8CKS0KuYsjVBDRsNiZvQP2658BuEEEIIJ0hC9wB1xXUQEob50Zvo/LOeDkcIIYQXkITuAcri\ni/G3+yDzGHr5J54ORwghhBeQhO4hqn0XVK8Y9Df/Qx9z3QYzQgghaidJ6B6kbrwDfOtgfjiPGr7p\nnRBCCA+ThO5BKsiKGnEL7EqEhI2lzuvcM+jDBzwQmRBCiJrmohJ6YWEhRUVFro6lVlKDroWwVpiL\n30bn5RYf1xlHMf/9KOazD6P3/OjBCIUQQtQETiX0999/n9TUVAASExMZO3YsY8eOJSEhwa3B1QbK\nx8cxQO54JnrZxwDo/cmYzz8Op05CcFPMt19GZ5/0cKRCCCGqM6cS+tq1awkLCwNgyZIljB8/nkcf\nfZQPP/zQrcHVFiqyI6rfEPR3SzG/+QzzpSehbj2MSS9g3D8JcrIx35mFNk1PhyqEEKKaciqhnz17\nlnr16nH69GmOHj1Kv3796NatGxkZsnypq6i/3A5166GXLICwVo5d2kLCUC3CUTfdCTu2oeM+93SY\nQgghqimLM4VCQkKIj48nLS2Nzp07A5CdnY2vr69bg6tNVEAQxh2O5+Xq+jGounXPnRt4NXp3Evp/\ni9BtOqHC23gwUiGEENWRUy30u+66iy+//JKkpCRuvvlmwPEs/ffkLlxDdeuNMfruEskcQCmFcfuD\nEGjFfPMF9JkcD0UohBCiulK6hk+APnLEdYuyBAcHk5mZ6bLruZpO3Y354iRUrwEYdz7i6XDKVd3r\nsaaQenQNqUfXkHp0jcrWY2hoaLnnnGqh79q1i/T0dABOnDjBf/7zH+bOncvJkzLyuiqpyA6oYaPR\nm1Zjblrt6XCEEEJUI04l9LfeegulFACLFi0iLy+PoqIi5s2b59bgRGnqmhshsgP6g/+gM456Ohwh\nhBDVhFMJPSsri8aNG2OaJtu3b+e+++7j3nvvJTk52d3xiT9RPj4Ydz0KysCc/zL6twV+tNbofXsw\nv1qMzjnt4SiFEEJUNadGuderV49Tp07x888/ExoaSv369SksLKSwsNDd8YkyKFsT1K33o996Cb1k\nIdo/AB2/Co796ihgT0fdPsGzQQohhKhSTiX0K6+8kkmTJlFQUMCYMWMASE5OPu/DeeFeRq8BmDsS\nzs1Nb9MRddUo+Hk/+vtl6MuHolq382yQQgghqoxTCX3UqFH06tULwzCKk3hQUBD33nuvW4MT56f+\ndh9EdnBsxdqkGQA67ww6YSPmh/MwJr+IMnw8HKUQQoiq4PTmLKGhoWRnZ7Nx40aSk5Np1qwZrVq1\ncmNo4kJU3XoYA64sTuYAqp6fY1vWQ6no9d95MDohhBBVyakW+pEjR3jhhRc4c+YMNpsNu91O/fr1\n+ec//ynd7tWQ6jUAvfZr9P/eQ0f1QzUM8HRIQggh3MypFvr8+fOJiYlh3rx5PP/888ybN49Bgwbx\n9ttvuzs+cRGUUhh/vRdyc9BL3/d0OEIIIaqAUwl9//79XHfddcVz0ZVSDB8+nAMHDrg1OHHxVFgr\n1KBr0Wu/QR/c6+lwhBBCuJlTCd1qtbJnz54Sx5KTkwkKCnJLUMI11IhbILAR5vxX0GfPejocIYQQ\nbuTUM/Sbb76ZGTNmEB0dTePGjcnIyGDbtm088MADTt8oKSmJBQsWYJomQ4YMYeTIkWWW27RpEy+/\n/DLPP/88ERERTl9flKb8GmDc8TDmK/9CL1ngGBUvhBDCKznVQu/Vqxf//ve/CQkJ4dSpU4SEhDB9\n+nR69erl1E1M02T+/PlMnjyZV155hQ0bNnD48OFS5XJzc1mxYgVt2sj2oK6iOnZDXXEdevVy9I9b\nPB2OEEIIN3GqhQ4QFhbGTTfddFE3SU1NJSQkhKZNmwLQr18/tmzZQlhYWIlyixcv5rrrruOLL764\nqPuIsqnrx6B3b8dcOBtj6muoAHlUIoQQ3qbchP7GG284dYHx48dfsExWVhY2m634tc1mY+/ekgO1\n9u/fT2ZmJlFRUedN6HFxccTFxQEwY8YMgoODnYrTGRaLxaXXq04KH5uG/fE7sXw4l6AnXywe4OgO\n3lyPVUnq0TWkHl1D6tE13FmP5SZ0q9XqlhuWxTRNFi1a5NSPg9jYWGJjY4tfu3J/Xq/e77dBIGrU\nGPIXv03G4gUYsSNKFdGmiV6yAIKbYgwedtG38up6rEJSj64h9egaUo+u4c790MtN6KNHj77oG/6Z\n1WrFbrcXv7bb7SV+MOTl5fHLL7/wzDPPAI4911944QX+8Y9/yMA4F1KDh6H3/Ij+5B10aAtUx+4l\nzuvPP0B/9znUb+BYC963jociFUIIUVFOL/1aGREREaSlpZGenk5hYSHx8fFER0cXn/fz82P+/PnM\nmTOHOXPm0KZNG0nmbqAMA+OuR6BZC8y5L6CPnhuYaG78Hr38E2jdzrEgTdIPHoxUCCFERVVJQvfx\n8WHcuHFMnz6diRMn0rdvX1q0aMHixYvZunVrVYQgfqPq+WH8fQpYLJivPYfOyUan7kIveg3adcZ4\nbDoE2dAbV3k6VCGEEBWgtNba00FUxpEjR1x2rdr0jEjv3YU5cwqEt4Wjh8GvoWN3tgb+mP97F/3N\nZxgvLkAFNKrwtWtTPbqT1KNrSD26htSja7jzGXqVtNBF9aPadETd9gCk7gLTxJjwFKqBv+Nc38Fg\nmujNaz0cpRBCCGc5NQ99zZo1ZR739fXFarUSGRmJxeL0lHZRTRiXDcG0WFAhYaiQ5sXHVbMW0KoN\nOn4VXHGdByMUQgjhLKeycFxcHPv27cPf3x+r1UpWVhbZ2dmEh4eTnp6OxWLh8ccfp3Xr1u6OV7iY\n0TumzOOq7yD0R2+ifzmAahFexVEJIYSoKKcSenh4OL1792bYsHNzk5ctW0Z6ejrTpk1jyZIlLFiw\ngGnTprktUFG1VM8B6I/fQW9chWpxp6fDEUIIcQFOPUNft24d11xzTYljV199NWvXrsUwDK6//np+\n+eUXtwQoPEP5B0DnaPTmNeiiIk+HI4QQ4gKcSugBAQEkJiaWOJaUlERAQAAABQUFGIaMr/M2Rr/B\ncOoE7ErydChCCCEuwKku97FjxzJr1ixatWqFzWbDbrdz8OBBHn74YQBSUlIYOnSoWwMVHtC5BzT0\nx/x4PurHLRBkhSArqnU7x8A5IYQQ1YbT89BPnjxJQkICx48fJygoiB49ehAYGOju+C5I5qG7l/n9\ncvSaFXAiC3KyHQctvhiPPoeK7FDme6QeXUPq0TWkHl1D6tE1PLKW+58FBgYyaNCgiw5C1EzGoGtg\nkGP8hC7Ih8xjmK8/hzlnOsakF1FNmnk4QiGEEOBkQs/IyGDx4sUcPHiQvLy8Eudef/11twQmqh/l\nWweatcB48GnMGY9jzn4W44n/QzUMKC6jf95PbtJGdJfeKBlXIYQQVcaphD579mxsNhujR4+mbt26\n7o5JVHOqaSjG+CcxX56C+ca/MSZOgwMpmCuWwI5tnAKMe/8B0f09HaoQQtQaTiX0n3/+mWeeeUZG\nsotiqk1H1B0Po996CXPS3XAyC/wDUSNvxdi2gaLPP8Do3hfl4+PpUIUQolZwKkO3b9+eQ4cOuTsW\nUcMYvQagbhwH9f1Qo+/BeP5tjGtvouHf7oGjv6LjV3o6RCGEqDWcaqGHhIQwffp0+vTpQ1BQUIlz\nN9xwg1sCEzWDMXQkDB1Z4ljdXgMgvC36y/+i+wx0PHsXQgjhVk610E+fPk3Xrl3Jzc0lLS2t+M/R\no0fdHZ+ogZRSGNffBscz0d8vd8k1a/guv0II4XZOtdAnTJjg7jiEl1EdukKHrugVn6AvH4qq73fR\n1yp67hFUpyjUyFtdGKEQQniXclvodru9+O+ZmZnl/hGiPMb1Y+B0Nvq7pRd9DX3qOBxKRa/5Gl1Y\n6MLohBDCu5TbQp84E0m+TQAAIABJREFUcSKLFi0C4IEHHij3AosXL3Z9VMIrqPA2ENUP/e3n6AFX\nooJsFb/IgVTH/54+BTsToGsv1wYphBBeotyEvnDhwuK/f/TRR1URi/BCxqgxmDu2Yc57AePR6SiL\n04sTAqAP7gVlQIMG6I3foyShCyFEmcrtcv/jnHPDMMr9I8T5qKahqDF/h9Td6E8XVvj9+uBeaBaG\n6hWD3v4D+sxp1wcphBBeQJZ+FW5n9I7BPJCCjvsCs3U7jJ6XF5/TB1LQ3y9DXXMjKiSsxPu01nBw\nL6pLT1TfQehVX6G3bkANuLKqP4IQQlR7svSrqBLqhrHoQ6nod19DN28JFl/0Z++ht653FGjgj7r5\nrpJvsqc7np23agMtIyEkDL3pe5CELoQQpcjSr6JKKIsvxr3/wJw2EfPlp+B0Nvj4oIbdjN67C73j\n/9u78/goq3vx45/zzCSBBEjIZCNsIQtrEAwgEVxAuHorcmut+9VC7U+vcItCb7VcWitt9Ra0COJS\nrCDKdSm8eitaS2ulqCiIsgthSyAkgQSyTICwhCzP+f1xkiGTdRKy832/XryY5VnOPDzMd872Pduh\nekA/mmr2jUlAKYVKnoBe+zY67wQqPKr1P4QQQrRjkvpVtBoV4sJ65EkoLUWNuwnr2WVY3/131Mix\nJlVsnneiIn00FRxO6BNj9k82y/fqrz9r5ZILIUT7J6lfRatSgxKxlryDUurSa4lJ6NWgU3aiJnzH\n87o+mgZ9YlB+fmY7VzgMGo7+6jP0lHu8jiGEEFc6Sf0qWl2NQBzZG8IiTbN7BW3bkJFm5rJX3Td5\nAuRmQ/qhOo+v0/ZhN1PKWSGE6Cgk9atoc0opU0v/6lN0WSnK6Qcnj0PxBTMgruq2o8aj330NveVT\nVOygWo9n/3UN7N2B7hGCGjWuNT6CEEK0OUn9KtoFNSwJLhZD2n6gorkdMyDOa7uugTB0JHrf7lqP\no20bDh8EwF71MrqwoNbthBCis5HUr6J9GHwVOJzovdtRg68yI9wDukCvPjU2VQOHmSQzpwtRwT29\n38zOhAvnUFPuRn/yAfbKJVizf4Vq4xka9sfvQ/F5rO/+e5uWQwjReUnqV9EuqC5dIWEoeu8OuPOH\nZoR7v1iU5ai5bUIiGtCHUlBjrvN6T6ftM9uMnwyhYej/fRW9/kNUtTXbW5PWGv2P96G0BH3bvShH\nzc8khBCXS1K/inZDJSbB8Qx0/knISqd6c7tHv1hTe0/dW/O9tP0QHAphkajrb4GRY9Hvr0JnpV9W\n2S5rPfbjR+HMKbhwHrKOXFY5hBCiLj4NirNtm08++YR9+/ZRVFTk9eX29NNPt1jhxJVFJY5C/+lN\nT222+oA4z3YOB8QNQR9KqfGeTtsP8YM9I+mtH/wY+1ePYa94AeuXLzap6V2fO4v91AzU96dhjZ/c\n+P337br0+NBe6vyhIoQQl8Gnb7e33nqLv/3tb8THx5OamkpSUhJut5vBgwf7fKJdu3bx+OOPM2vW\nLNaurbk+9kcffcScOXP46U9/yq9//Wvy8vJ8/xSic4juByEu9BefADUHxFWlBg4ztflzRZ7XdGEB\nFOSi4odc2q57MOp7D8LxjHqnutUr8zAUnUa/uwydc6zRu+uUXdCrL0RE1/ojRLQcbZdTLgMjxRXC\np4C+ZcsW5s2bx9SpU7Esi6lTp/LEE0+wf/9+n05i2zYrVqxg3rx5LF68mE2bNnHsmPcXY0xMDAsW\nLOB3v/sdycnJvP32243/NKJDq5y+RlkpBHWHetK7qoGJ5kHqpQCpK0bIq/ih3tuOTDYD7nZ81aRy\n6eMVWRIdTuzli9Blpb7vW1oCqSmooSNRgxLhUAraLm94v327KJgzDX2xuMFtm6p82QLsNSta7Pjt\ngd70T/Jn3IU+f66tiyJEi/MpoJeUlBAeHg5AQEAAJSUl9OnTh/R03/ol09LSiIqKIjIyEqfTybhx\n49i6davXNomJiZ6FXxISEnC73Y35HKKTUIlJ5kH/+PozwcUkmAVeqtZ4D+8H/wDoM8D7mEHdYMhV\n6B2bm9YXnp0J3XpgTX8cMg+jP3zX933T9kNpCWrY1TAwES6cg2NHG9xNf7ORsqOpLdbnrrWGfbvR\nWz4zU/06q8wjZjpkXk5bl0SIFudTQI+Ojubw4cMAxMbG8qc//Ym1a9fSs2fPBvY03G43LpfL89zl\nctUbsDds2MDIkSN9OrboZIaMAD9/VMKQejdTfn4QO8groOvUfTBgIMpZc2iIShoH+SebFCD18Qzo\n3R+VdC3q+pvRf/8z+mAtA/Jq2zdlp8lHPzDR06qgDzW8r65oedCZLTSI7vxZ8+Oi6LTpjuikdG62\neZAnWS1F5+fToLhp06Z5RrT/4Ac/4A9/+AMXLlzg4YcfbvYCbdy4kSNHjjB//vxa31+/fj3r168H\nYMGCBYSFhTXbuZ1OZ7Me70p1edcxjLKl7+DoGYZqYKnesyPGcO7/3iI0qCugyDt2lKDv/4ButZzb\nnnQreW//nq77dtItaazPpdG2TV52Fl0m3UqPsDDsGU/iTtuHfvNFQhe/hdWtR737F6TuRQ0eTmhv\nM58+PzIaZ/ohQuq5PuXuPPJzTY0yIDeb4Ba4J0sLc6n8SR2YkUrQ1WOa/RztQV7+SWwg8HwRQfJ/\n+7LI92PzaMnr2GBAt22bnJwcxo0zKTSjo6PrDLZ1CQ0N9co8V1BQQGhoaI3tvv32W95//33mz5+P\nX8WCHNVNnjyZyZMvjTRuzmx1YWFhkv2uGVz2dXQGQFGR+VMP3WcA2DYFX28ChwPsci5E96e4rnMP\nHMa5Tf/kwi3f93lhF51/El18nuLQCEoqjqt/OAf7t0+Qv+ZNrH+7v+59z5zCPnIIdfsDnuthxw/h\n4q5vyMvNrXPEvb3VrBFvhYRSnLqP0ha4J+00k02PgC6c3bqJC9fd3OznaGu6tBQ77yQA5zKOcEH+\nb18W+X5sHpd7HaOjo+t8r8Emd8uyeOONN+oMsL6Ii4sjJyeH3NxcysrK2Lx5M6NHj/baJj09nddf\nf50nn3yS4ODgJp9LXEHiBoPDgT601zS3KwV15HcHTF73E8chO8v3cxzPNPtG9790nAEJ0D8OfeDb\nenfV+016WjX06ksvDhwO54ogu55m7kMpENCVLjfcDNmZjRqE57OKFgB1zQ2QmmIG73U2+SdBm/EB\n1ZfmFaIz8qkPPSkpiR07djT5JA6Hg4ceeohnn32WOXPmcO2119K3b19Wr17Ntm3bAHj77bcpLi7m\nhRde4IknnmDhwoVNPp+4MqiALtA/Hp2agj68H3rHoAKD6t7+6mtBKfSOzT6fQ1cG3uh+3scalAjp\nh9AXL9a9875dZrR+/1jv/QB9sO7pa/rQXogfjF/8ECgrgyZMlWtQ/kkI7okaMdbM+U/zbcZKc9K2\njb16OTrjcMucoKL/3BEZbT6vEJ2cT33oWmsWLVrE4MGDvQa3AcycOdOnEyUlJZGUlOT12j333ON5\n/NRTT/l0HCGqUgnD0Os/BKcf6tqJ9W8b3NMkpNm+Cabe69sJjmVAaHiNHwpq0HD0x+/DkQNmIF81\nWmv0vl2owVd5pa9VrghwRaAP7YFJt9Xcr+gMZGeirrkBZ8XSsTrzCKrvgBrbXg6ddwLCImHQMNPK\nsW8XqpbP0aIyD5t/u/IyVP+4Zj+8rmiF8B85lguffIAuL28w7a5250P6QbhqDMrPv9nLJERL8qmG\nHhUVxdSpU0lISCA0NNTrjxBtSQ0cBuVlcPECxNc/Mh4qmt2PZ6BPZvt0fJ1tRrjXED8UlFX3iPWc\nLDhVAMOurvGWGlgxH722KXSVuegHJuLo1ddMw2uJqWt5J1DhvVBdAs1sgSrZ7FqL3rPd/N2SNfTA\nIPziB4Ntg7v2ZFU64zD2B+9Q/uvHsX/2EPayhejP/94yZRKiBdVbQ//yyy+57rrruPdeH2szQrS2\n+CGm71zrGgllaqOSrkWvXo7esRn1nTvr3VaXlcGJY2Zp1+rH6Rpo+tEP7ql934oAqYbWMv1yUCJ8\ntcH05ff2bsrXh1LAzx9iEkxtsu8AdDMHdF1aCoX5EB7pKaP+8D100RlU9/pH7TdrOfaY7jaOpftU\ne2708U9mQ0Q0jqje5oX8kzWSFen0VOz/+S9QFsQNRt0xDf3Fx+bHxuR/a9byCNHS6q2hv/76661V\nDiGaRAV2gz4x0DMM5QpvePvQcBgwEL3dh370vBzTh11bDZ36+9F1yk6IiDZN7NX388xHr/ljQKem\nQOwgM88eTFN7VnqTkr/oA9+iz52t+UZBLmgN4b3MOYaMBK3RB2pfY74l6DOnzBK5UX2gpAROtMA4\ngdwcVES06UOn9oFx+ogZ7W/95lUcP1uA9Z3vm3EFh/a2aJY+IVpCvQH9slaYEqKVWPc+jPXgf/q8\nvRo9HjLSsDd+XO92+pgZEKfqDOjDTcA/csB7v1MFsG8n6uo65ruHRULPMKiWnEZfOA+ZR1AJwy69\n2DfWrNLWyEFd+pQb+4Wn0B//ueabFYFNVdTQiUmArkFmEF8r0Xt3mFaVKXeZ5xlpzXv80lLTxB7Z\nCys03CT3qW2ke9YR6B4MEb08L6nhFemHD9Te+iJEe1Vvk7tt2+zdW39Wq8TExGYtkBCN5cnr7uv2\nE6eg93+L/t9XsG0ba8J3at8wO8M0xfbqU/v7VfrRqw4o0xv/YYLVDf9a+/mVQg0Zgd6+CZ2TherV\n17yRth+0bcYFVG7bLxYNJvBUCToN0ft2mVp3LQvS6PyKwFZZQ3c4YPBw9L5daK19nqN/WfZuN6Ps\nx9yAfvv3JkXruEnNd/z8E6YVIqKX+XyuiFoDus5Kh74DvD9zQiL4B6D3bkeN6JwJd0TnVG9ALy0t\nZdmyZXXW1JVSvPzyyy1SMCFaivLzx5o5D3vZAvQ7v8e2y7FuqmXE+fEMiOxV52jn2vrRdVkZeuPH\nMCwJVU8AVt/9d/Sebdiv/hZr3u9QXQPRqXtNgpyqc+l79wfLQmemo0aN9/1D7q+obWekoW3bO4lN\n7gkz2K5HyKXyDB2J3rkFTmZDZZ9zC9Hl5eiUHairky+NE/Cxhl7ZvdFQFkEqBj2qiIokHOGR6Gqt\nHLqsDLIzUJOmer2u/Pxg8FXovdtb7weOEM2g3oDepUsXCdiiU1J+flgz5mK/9hz6vT9gl5dj/ct3\nvTc6nmn65+s7zqBE9D//gr540QSZ3V/DaXeDXQAqNAzrP57EfuEp7DdfxHp0rhkQF5Ng5td7yukP\nvfo2amCctm1TQw/oYprrc7NNX3Xl+/knIDzKK1CpoVejAb1/F6qFAzqHD8D5c6jhpvar+sejv/wE\nbZd7TfGrjf3KM6AsHHN+Ve92lVPWqOg/V+FR6PRU741OZJkuk76xVKcSR6G/3Qonj3tdOyHaM5+m\nrQnRGSmnH9Z//AySxqHXrEDv3e55T1+8CHk5dfafe45RrR/d/nSdad4dXnNkfG37qjt/CDu+Qn/4\nHhxN8+4/r9yub6xpkvbV8Qw4cwp1o2ny10erBbLKOehVzxHRC8Ii0Rv+iv315y06IEzv2WZaIiq7\nKfrFmhXRGphKqLMzYf9uSEtBlzewBG1uNgR2QwV1N8/Do+D8Wa9BgjrTrBap+tUW0M2/X9V7Qoj2\nTgbFiSuacjqx/t9/QUQ09nuvm8FUYGpvWjcY0Kv2o+ucLDi4B3XjvzZY0/Scf/K/ocZcj/7ojybB\nysCaAZ1+sXDajT5T6NMx9b6d5tiTpoK/Pxy91JyttfbMQa9RljumQfEF9PJF2D95EPv1RegdX6HP\nnvHpvL7Se7ZB/FBPsh7VP9683kCzu64cxFhSYpa0rW/b3BxP7RxAhVVMV6va7J6Vbq5PZM3c2Co8\nCqJ6o/c0PUOmEK2t3oC+atWq1iqHEG1G+flh3fcw5Gaj138AVPSfQ4154jX2rdKPrj9dB04navzk\nevfx2l8p1LRZnr5y4momx/FkiauoUTZEp+w0y72GhkO/OO8a+plTUHLRMwe9KmvMdVgLV2D99H9Q\nyRPQe7dj//632HMeoHz+LOx3ll12AhpdkAfHM1DDq6zlENXHBNaMulshdMlF9FcbzIh8aml1qO5k\ntvcYhsr55/mXBsbprCMmXXAdP75U4qiK6Wv1pPcVoh2RJnchqPjyHpmM/mi1Sf95PBOcfp6R4PXu\nOygRjhxCf7UBNWo8qspgM5/OHdAFa/avsB57uvZc9BV9vL70o+uSi5C6z5PQRsUkQOYRMwAMqkxZ\nq/1zKctCDUrEevA/sRa9hfXkAtTtD0BIKPqrT7GXPH1ZzdCV+6rhoy6d0+GAPgPQmXXX0PW2TXD+\nHNb3p0FgkFerQ41tS0tM4pyIKjXvii6GyrnoWmvIqj+lrkocZaavHax/ER4h2gsJ6EJUsO75kZnq\n9aeV6ONHIbqvT9nL1KDhJv1s8QXUhFubdG4VEoqqJU0sgArqZvrlfelHT90HZaWXMtTFJJjFVyqa\nqD3JVWqpodc4r9MPlTAUa8rdOGb/CmvRKujdH3v5C6am3QR6zzbzWSqn6lWeq3+c+eFRRwIdvfHv\nENkbBg03C/LUV0PPuzRlzXP8roHQrQdULKeKOw/On6t1QJzHwGGe6WtCdAQ+Lc4ixJVAhUWivnMn\n+sN3wc/f92liFf3o9O5vlnRtCf1i0ZUZ41JT0Jv+iT64B+uh2eYHRQW9byc4nWYuNaaGrjFN1Kpf\nrAl2SoGr4YBenQoIwHp0LvYzc7BfW4j15G9RTpPRTmuN3rQeveEj6BqECgmFEBf0CIbSUig+D8UX\nYP8u1LjJNaeC9YuDT9eZZV2rjbLXxzPg8AHUXT80XRQxCeh/vI8uLal9SmHFKmuqet94eNSlOfgV\nrR311tD9/Cumr+2Q6WuiQ5CALkQV6pbvoTf/0wyeaqD/3LNP10DUfQ+j+gxosS991TcWvetr7HmP\nmNStXQPBPwD79UVYT7+I6h4MVPSfJwy7NE87opdpos5IA24xAb2ny5NattHliIzG+uHj2L9fgF7z\nBur+/0CfKcRe9Qrs/sYM4NO2SWhTWGCarMF0X3TpCiFhqHE31Txu/3jzwyMjrca0Of35383YhGtN\n4hkVE29GuWele8/Zr9z+ZMWUtQjvgK7CIj01e52Zbn7YNDQt0TN9reXn5wtxuSSgC1GF8g/AuvcR\n7Jd/gxpQM1jUxZo4pQVLhcks99fVENkb9b0HUSOTITcb+39+iv3GEqxZT5kBb8czUGMnXNpPKa8m\najMH3feMc7WWJWkc6l++i/7kA2yHA73lM7hYjLrnR6ibpnqS2GitTa3czx/lbOCrpldfE/Qzj8DY\nGz0v64sX0Vs+QyWNv7RwTJWBcaqWgE5uDgR1N10VVYVHwY7NJrFNVjpERnvN+a/1syYmmR8ae7a1\n/Px8IS6TBHQhqlEjxmD97i2zfno7oeKHYL36f94Z3/oOQN39I/S7y8y64hW1dDXMe4W3qk3U5J0w\ng70utzx3TEOnHzLn7R+P9aM5l1LYVm6jlGlJ8OV4Tif0iakxdU1v+wIunEPdeMulF3uGmSx3dfSj\n69zs2tPkhkVCebkZMJd1pPYfA9XLFR5lEvt8uxWqJx4Sop2RgC5ELdpTMK/kFcwrX5vwHfT+Xeg/\nr4K+A0xQ7+PdL6xiEkwTddp+OF1YYwnRJpXF6cSa+XOTwnX0dQ3XwH05Zv849DdfePqrdXYm+q9r\nTO29SsIdpRTEJKDrGumem11rfn8VHmXy4mekmW6LG+vI4V99vxHXoD9Ziz5/rvZZCEK0EzLKXYgO\nTCmFNe0xCO4JR1NRQ0bUDPyVTdTbNpnnzRDQAVT3HljJE5olmANmYNyFc5CXg73x79jP/gSKL2A9\nMKPG2AQVkwAnjqGLz3u9rksugju/Rv854PncescWc4x6BsR5nWvEGKjIPy9EeyYBXYgOTgV1w3r4\np2Z0+8jkmhv0dEFwT/QOE9DrmoPe1iozxtkvP4v+31chfijW00trr23HJJipaRmHvd+onJZWW5N7\nTxc4HOg9W83zfr4FdGIHmSlvu77x8ZMI0TakyV2ITkDFD8Fa/I5ZkKX6exVN1OyuCEg+zEFvE737\nmR8ludmoO6ej/uX2WrsZAO+BcVWm7XmmrNVSQ1dWxTKquTlm6dYevnWrKMuBGj4avfsbdHm5T7kJ\nhGgLUkMXopNQXbrWOW1OxZjaL12DoHLBknZGOf2w/vPnWPN+h3XLHXUHc0xzP64IqLaCmj5x3Dyo\na+naypzu9SWUqe18I66B82fNOAQh2ikJ6EJcAVRFjZbwyHadIEUljkL1i/Nt25gEr4xxuiAP/Y8/\nQ7+4mlPWKvepaJ3wtf/cY9hIcDrR30qzu2i/JKALcSXoXxnQm2dAXLswIAEKctFFp9GlpdivLYTy\ncqxHnqh7n/Am1tC7BMKg4WjpRxftmAR0Ia4AqnsPVPIEk5Cmk6gcRMfRNPSaFZB+CGv64zVTvlbd\nZ8Ag8PdHxfmeNMiz74hrzIp8J441tchCtCgJ6EJcIawf/QQreUJbF6P59I8HpbA/eAf92TrULd9D\nJV1b7y5q4DCsl1abpWUbSV01BgC9e2uTiitES5OALoTokFTXQLMCW0YaDExEfe8Hvu1Xx/rnDe7n\nijDLvO7+ukn7C9HSJKALITosNXg4hLiwHnmiVaaTqRFjIO0A+uyZFj+XEI0lAV0I0WGpex7Geub3\nrZaqV424xqwmt0fWSBftjwR0IUSHpZzOBldMa1b948266h+8gy6SWrpoXySgCyGEj5RlYT38BJwu\nxH79ebPojRDthAR0IYRoBDUgAfXATNi/26xyJ0Q7IbnchRCikazxk7AzUtH/eB+7XyzW2BvbukhC\nSA1dCCGaQt39I4gfil71EvrwgbYujhCtV0PftWsXK1euxLZtJk2axO233+71fmlpKS+//DJHjhyh\ne/fuzJ49m4iIiNYqnhBCNIpy+mE9+jPsZ36CveBJSBiKuuEW1KjxKD//ti6euAK1SkC3bZsVK1bw\ni1/8ApfLxX//938zevRo+vTp49lmw4YNBAUF8dJLL7Fp0ybeeecd5syZ0xrFE0KIJlHBPbF++SJ6\n0yfojR+jVyxG/3E5atjVEBoOPV2o0DAIdkGPEOgRgvLza+tii06qVQJ6WloaUVFRREaalY7GjRvH\n1q1bvQL6tm3buOuuuwBITk7mjTfeQGvdrleGEkII1b0H6l+/j775e3BwD/qLf6CPHITtm6G8DF19\nh65BENQNLAc4HGBZ5o9SoCr/rvjeq1xCVilAQeXXYeVzz+OqBVI1X6ttO/NivU+r7lPo5095aakP\nx7wMvhyvI8SEKmVU/l2wHv6vVjltqwR0t9uNy+XyPHe5XKSmpta5jcPhIDAwkKKiInr06OG13fr1\n61m/fj0ACxYsICwsrNnK6XQ6m/V4Vyq5js1DrmPzaNXrGDEJrp8EgLZt7DOnsPNPUu7Oxz7lxj7t\nxj5ViD5XZKa82TaUl6PtctC6yh+72nON1lV+GlQ+9rymL/1VuX9VWtf/vBa62jb6YjFOr9caOEbD\np2h0mRp/0OY4Z2OP6f1UdQ0ktMr915L3Y4cb5T558mQmT57seZ6fn99sxw4LC2vW412p5Do2D7mO\nzaPNr2NIuPnTwbna+jp2UBrvOHW592N0dN2rCbbKKPfQ0FAKCgo8zwsKCggNDa1zm/Lycs6fP0/3\n7t1bo3hCCCFEh9cqAT0uLo6cnBxyc3MpKytj8+bNjB492mubUaNG8dlnnwGwZcsWhg0bJv3nQggh\nhI9apcnd4XDw0EMP8eyzz2LbNhMnTqRv376sXr2auLg4Ro8ezU033cTLL7/MrFmz6NatG7Nnz26N\nogkhhBCdgtLVRz50MNnZ2c12rDbva+sk5Do2D7mOzUOuY/OQ69g8OnwfuhBCCCFaVoevoQshhBBC\nauhe5s6d29ZF6BTkOjYPuY7NQ65j85Dr2Dxa8jpKQBdCCCE6AQnoQgghRCfgmD9//vy2LkR7Ehsb\n29ZF6BTkOjYPuY7NQ65j85Dr2Dxa6jrKoDghhBCiE5AmdyGEEKIT6HCLs7SUXbt2sXLlSmzbZtKk\nSdx+++1tXaQOIT8/n1deeYVTp06hlGLy5MnceuutnD17lsWLF5OXl0d4eDhz5syhW7dubV3cds+2\nbebOnUtoaChz584lNzeXJUuWUFRURGxsLLNmzcLplP+29Tl37hzLli0jKysLpRQzZswgOjpa7sdG\n+uijj9iwYQNKKfr27cvMmTM5deqU3I8NePXVV9mxYwfBwcEsWrQIoM7vQ601K1euZOfOnQQEBDBz\n5szLao6XGjrmS3TFihXMmzePxYsXs2nTJo4dO9bWxeoQHA4HDz74IIsXL+bZZ5/l448/5tixY6xd\nu5bhw4ezdOlShg8fztq1a9u6qB3CunXr6N27t+f522+/zZQpU3jppZcICgpiw4YNbVi6jmHlypWM\nHDmSJUuW8Pzzz9O7d2+5HxvJ7Xbzt7/9jQULFrBo0SJs22bz5s1yP/pgwoQJzJs3z+u1uu6/nTt3\ncuLECZYuXcojjzzC8uXLL+vcEtCBtLQ0oqKiiIyMxOl0Mm7cOLZu3drWxeoQevbs6flF2bVrV3r3\n7o3b7Wbr1q3ceOONANx4441yPX1QUFDAjh07mDSpYj1trUlJSSE5ORkwXxRyHet3/vx59u/fz003\n3QSYtaeDgoLkfmwC27YpKSmhvLyckpISQkJC5H70wdChQ2u0/tR1/23bto0bbrgBpRQDBw7k3Llz\nFBYWNvnc0laC+TXqcrk8z10uF6mpqW1Yoo4pNzeX9PR04uPjOX36ND179gQgJCSE06dPt3Hp2r83\n33yTBx54gAsXLgBQVFREYGAgDocDMEsMu93utixiu5ebm0uPHj149dVXycjIIDY2lunTp8v92Eih\noaFMnTqVGTNm4O/vz4gRI4iNjZX7sYnquv/cbjdhYWGe7VwuF26327NtY0kNXTSL4uJiFi1axPTp\n0wkMDPR6TymWEcPQAAAGXUlEQVQlS+E2YPv27QQHB8u0oMtUXl5Oeno6N998M8899xwBAQE1mtfl\nfmzY2bNn2bp1K6+88gqvvfYaxcXF7Nq1q62L1Sm05P0nNXTML82CggLP84KCAkJDQ9uwRB1LWVkZ\nixYt4vrrr2fs2LEABAcHU1hYSM+ePSksLKRHjx5tXMr27eDBg2zbto2dO3dSUlLChQsXePPNNzl/\n/jzl5eU4HA7cbrfclw1wuVy4XC4SEhIASE5OZu3atXI/NtKePXuIiIjwXKexY8dy8OBBuR+bqK77\nLzQ01GvltcuNPVJDB+Li4sjJySE3N5eysjI2b97M6NGj27pYHYLWmmXLltG7d29uu+02z+ujR4/m\n888/B+Dzzz9nzJgxbVXEDuH+++9n2bJlvPLKK8yePZvExEQee+wxhg0bxpYtWwD47LPP5L5sQEhI\nCC6Xy7Os8p49e+jTp4/cj40UFhZGamoqFy9eRGvtuY5yPzZNXfff6NGj2bhxI1prDh06RGBgYJOb\n20ESy3js2LGDt956C9u2mThxInfccUdbF6lDOHDgAL/85S/p16+fpxnpvvvuIyEhgcWLF5Ofny/T\nhBopJSWFv/zlL8ydO5eTJ0+yZMkSzp49y4ABA5g1axZ+fn5tXcR27ejRoyxbtoyysjIiIiKYOXMm\nWmu5HxtpzZo1bN68GYfDQUxMDI8++ihut1vuxwYsWbKEffv2UVRURHBwMHfffTdjxoyp9f7TWrNi\nxQp2796Nv78/M2fOJC4ursnnloAuhBBCdALS5C6EEEJ0AhLQhRBCiE5AAroQQgjRCUhAF0IIIToB\nCehCCCFEJyABXQjR7HJzc7n77rspLy9v66IIccWQgC6EEEJ0AhLQhRBCiE5AcrkLcYVwu9288cYb\n7N+/ny5dujBlyhRuvfVW1qxZQ1ZWFpZlsXPnTnr16sWMGTOIiYkB4NixYyxfvpyjR48SGhrK/fff\n70n5WVJSwh//+Ee2bNnCuXPn6NevH0899ZTnnF988QWrV6+mpKSEKVOmeDIwpqWlsXz5cnJycvD3\n9+e6665j2rRprX5NhOhMJKALcQWwbZuFCxcyZswYZs+eTUFBAb/5zW+Ijo4GzLrMjz/+OLNmzWLd\nunU8//zzvPjiiwAsXLiQiRMn8otf/IIDBw7w3HPPsWDBAqKjo1m1ahXHjh3jmWeeISQkhNTUVK+V\npA4cOMCLL75IdnY28+bN45prrqFPnz6sXLmSW2+9lRtuuIHi4mIyMzPb5LoI0ZlIk7sQV4DDhw9z\n5swZ7rzzTpxOJ5GRkUyaNInNmzcDEBsbS3JyMk6nk9tuu43S0lJSU1NJTU2luLiY22+/HafTSWJi\nIklJSXz55ZfYts2nn37K9OnTCQ0NxbIsBg0a5JXb+6677sLf35+YmBj69+9PRkYGAE6nkxMnTnDm\nzBm6dOnCwIED2+S6CNGZSA1diCtAXl4ehYWFTJ8+3fOabdsMGTKEsLAwXC6X53XLsnC5XBQWFgJm\n5S3LuvTbPzw8HLfbTVFREaWlpURFRdV53pCQEM/jgIAAiouLAXj00UdZvXo1c+bMISIigjvvvJNR\no0Y118cV4ookAV2IK0BYWBgREREsXbq0xntr1qyhoKDA89y2bQoKCjzLOObn52Pbtieo5+fn06tX\nL7p3746fnx8nTpzw9Lf7qlevXsyePRvbtvnmm2944YUXWLFiBV26dGn6hxTiCidN7kJcAeLj4+na\ntStr166lpKQE27bJzMwkLS0NgCNHjvD1119TXl7OunXr8PPzIyEhgYSEBAICAvjwww8pKysjJSWF\n7du3M378eCzLYuLEiaxatQq3241t2xw6dIjS0tIGy7Nx40bOnDmDZVkEBgYCeLUCCCEaT5ZPFeIK\n4Xa7WbVqFSkpKZSVlREdHc0999zDgQMHvEa5R0VF8eijjxIbGwtAVlaW1yj3++67j2uuuQYwo9zf\nffddvvrqK4qLi4mJieHnP/85p06d4sc//jHvvfceDocDgPnz53P99dczadIkli5dyrfffsvFixcJ\nDw/n3nvv9RxTCNE0EtCFuMKtWbOGEydO8Nhjj7V1UYQQl0HauIQQQohOQAK6EEII0QlIk7sQQgjR\nCUgNXQghhOgEJKALIYQQnYAEdCGEEKITkIAuhBBCdAIS0IUQQohOQAK6EEII0Qn8f2Ok9hRAZ9GT\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "acc = history_callback.history['acc']\n",
    "loss = history_callback.history['loss']\n",
    "ax1.plot(acc, label=nnet)\n",
    "ax2.plot(loss, label=nnet)\n",
    "    \n",
    "ax1.set_ylabel('Training accuracy')\n",
    "ax2.set_ylabel('Training loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "#ax1.legend()\n",
    "#ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kY7FCrov0G0h",
    "outputId": "6d0bc020-26d4-4bc1-a06f-b7077e9a017b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 258us/step\n",
      "Test loss: 0.05426451741853574\n",
      "Test accuracy: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "score = nnet.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = nnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ5zMBSP6GWR"
   },
   "source": [
    "##Average test accuracy rate in 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b8yNxaje0ywP",
    "outputId": "0b5a10d3-c591-4022-b538-a18ffa88e8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "766/766 [==============================] - 0s 644us/step - loss: 0.6538 - acc: 0.6527\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.6441 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 426us/step - loss: 0.6312 - acc: 0.6514\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.6152 - acc: 0.6671\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.5905 - acc: 0.7063\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.5699 - acc: 0.7206\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.5371 - acc: 0.7402\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 0.5362 - acc: 0.7324\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.5072 - acc: 0.7663\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.4803 - acc: 0.7846\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.4776 - acc: 0.8016\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.4707 - acc: 0.8003\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.4553 - acc: 0.8094\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 415us/step - loss: 0.4465 - acc: 0.7807\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.4128 - acc: 0.8277\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.4032 - acc: 0.8172\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 417us/step - loss: 0.4115 - acc: 0.8198\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 427us/step - loss: 0.3644 - acc: 0.8355\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.3510 - acc: 0.8277\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.3429 - acc: 0.8499\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 423us/step - loss: 0.4198 - acc: 0.7977\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.3338 - acc: 0.8525\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.3323 - acc: 0.8446\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.3080 - acc: 0.8747\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.2808 - acc: 0.8812\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.2576 - acc: 0.8903\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 457us/step - loss: 0.2760 - acc: 0.8812\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 0.2886 - acc: 0.8773\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.2278 - acc: 0.9073\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.2518 - acc: 0.8982\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1776 - acc: 0.9308\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.2211 - acc: 0.9138\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.2368 - acc: 0.9112\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.1871 - acc: 0.9204\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.2088 - acc: 0.9060\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.1921 - acc: 0.9360\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 424us/step - loss: 0.1943 - acc: 0.9269\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.1104 - acc: 0.9608\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.1787 - acc: 0.9386\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.1139 - acc: 0.9556\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.1500 - acc: 0.9373\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.1848 - acc: 0.9334\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.1205 - acc: 0.9543\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.0934 - acc: 0.9648\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.1542 - acc: 0.9399\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 0.1154 - acc: 0.9582\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.1481 - acc: 0.9439\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.1627 - acc: 0.9426\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.1234 - acc: 0.9621\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.1320 - acc: 0.9504\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.1169 - acc: 0.9543\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.0987 - acc: 0.9700\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.1251 - acc: 0.9439\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.1319 - acc: 0.9634\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.1234 - acc: 0.9530\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.2343 - acc: 0.9269\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 414us/step - loss: 0.0332 - acc: 0.9856\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.0177 - acc: 0.9974\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.1011 - acc: 0.9752\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.1715 - acc: 0.9399\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.0663 - acc: 0.9739\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.1186 - acc: 0.9569\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.0976 - acc: 0.9674\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.0470 - acc: 0.9817\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.0873 - acc: 0.9765\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.1615 - acc: 0.9373\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.0784 - acc: 0.9713\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.0381 - acc: 0.9909\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1469 - acc: 0.9504\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.1424 - acc: 0.9569\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.0648 - acc: 0.9817\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.0422 - acc: 0.9830\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.0643 - acc: 0.9778\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.2967 - acc: 0.9256\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1156 - acc: 0.9569\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.0543 - acc: 0.9765\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1039 - acc: 0.9556\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.1428 - acc: 0.9713\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.3153 - acc: 0.8903\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.0874 - acc: 0.9608\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.0300 - acc: 0.9896\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.0137 - acc: 0.9974\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 0.0157 - acc: 0.9974\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 8.1339e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 6.6860e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 5.7668e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 5.0248e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 4.5027e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 4.0654e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 3.6585e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 3.3379e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 3.0555e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 2.8293e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 2.6396e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 2.4793e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 2.3090e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 2.1523e-04 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 288us/step\n",
      "Test loss  0  :  0.05905018038174603\n",
      "Test accuracy 0  :  0.9895833333333334\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 692us/step - loss: 0.6482 - acc: 0.6514\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.6372 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.6334 - acc: 0.6501\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.6118 - acc: 0.6619\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 424us/step - loss: 0.5772 - acc: 0.7023\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.5524 - acc: 0.7232\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 456us/step - loss: 0.5201 - acc: 0.7533\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 430us/step - loss: 0.5297 - acc: 0.7415\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 434us/step - loss: 0.4600 - acc: 0.7911\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.4661 - acc: 0.8003\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.4659 - acc: 0.7768\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.4144 - acc: 0.8003\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.4221 - acc: 0.7950\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.3752 - acc: 0.8355\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.3691 - acc: 0.8590\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.3794 - acc: 0.8251\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.3398 - acc: 0.8525\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.3402 - acc: 0.8381\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.3080 - acc: 0.8655\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 0.2972 - acc: 0.8734\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.3016 - acc: 0.8655\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.2818 - acc: 0.8812\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 353us/step - loss: 0.2632 - acc: 0.8969\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.2914 - acc: 0.8708\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 359us/step - loss: 0.2136 - acc: 0.9112\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.2244 - acc: 0.9086\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.1759 - acc: 0.9282\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.2988 - acc: 0.8734\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.1783 - acc: 0.9243\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 359us/step - loss: 0.2728 - acc: 0.9099\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 436us/step - loss: 0.2254 - acc: 0.9230\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.1760 - acc: 0.9256\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.1620 - acc: 0.9347\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.1511 - acc: 0.9426\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.1739 - acc: 0.9399\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.1932 - acc: 0.9282\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.1327 - acc: 0.9465\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.1078 - acc: 0.9661\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.1174 - acc: 0.9556\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.0992 - acc: 0.9569\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 0.1593 - acc: 0.9465\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 428us/step - loss: 0.0878 - acc: 0.9700\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.1265 - acc: 0.9517\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.1029 - acc: 0.9621\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 352us/step - loss: 0.0866 - acc: 0.9582\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.1309 - acc: 0.9491\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.0932 - acc: 0.9700\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 418us/step - loss: 0.0936 - acc: 0.9634\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.0644 - acc: 0.9817\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.1622 - acc: 0.9504\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.1678 - acc: 0.9413\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.1155 - acc: 0.9569\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.0254 - acc: 0.9961\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.0068 - acc: 0.9987\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 8.9167e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 5.6094e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 4.3518e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 3.7972e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 3.2845e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 2.9649e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 2.6503e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 2.4328e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 2.2111e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 2.0520e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 1.9198e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 1.8049e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 1.6852e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 1.5969e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 1.5001e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 1.4283e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 1.3645e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 1.3070e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 1.2439e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 418us/step - loss: 1.1923e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 1.1464e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 360us/step - loss: 1.1029e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 1.0611e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 1.0272e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 9.8732e-05 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 9.5697e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 9.2172e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 8.9501e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 8.6404e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 8.3870e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 8.1789e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 7.9678e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 7.7717e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 7.5357e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 7.3343e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 7.1576e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 6.9974e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 6.8052e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 6.6559e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 6.5229e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 6.3543e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 6.2176e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 6.0804e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 5.9532e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 5.8510e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 356us/step\n",
      "Test loss  1  :  0.11086996675779422\n",
      "Test accuracy 1  :  0.984375\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 704us/step - loss: 0.6486 - acc: 0.6462\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.6491 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.6347 - acc: 0.6567\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.6176 - acc: 0.6697\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.5888 - acc: 0.6971\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.5664 - acc: 0.7272\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.5672 - acc: 0.7154\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.5595 - acc: 0.7206\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.5221 - acc: 0.7480\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.5340 - acc: 0.7454\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 0.4986 - acc: 0.7728\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 440us/step - loss: 0.4823 - acc: 0.7755\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.4576 - acc: 0.7977\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.4393 - acc: 0.7977\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.4179 - acc: 0.7885\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.4015 - acc: 0.8198\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.4332 - acc: 0.8016\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.4007 - acc: 0.8068\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.3640 - acc: 0.8303\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.3634 - acc: 0.8329\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.3243 - acc: 0.8655\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.3538 - acc: 0.8381\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.3783 - acc: 0.8211\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.3089 - acc: 0.8603\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 439us/step - loss: 0.2952 - acc: 0.8734\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.3081 - acc: 0.8642\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 0.2676 - acc: 0.8943\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.2548 - acc: 0.8969\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.2135 - acc: 0.9178\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.2229 - acc: 0.9138\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.2169 - acc: 0.9125\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.2082 - acc: 0.9151\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 451us/step - loss: 0.1783 - acc: 0.9282\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.1651 - acc: 0.9334\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.1806 - acc: 0.9347\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 0.1421 - acc: 0.9517\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.1342 - acc: 0.9517\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.1558 - acc: 0.9478\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.1284 - acc: 0.9556\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.1702 - acc: 0.9399\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.1617 - acc: 0.9334\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.1364 - acc: 0.9426\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 354us/step - loss: 0.0797 - acc: 0.9713\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.1201 - acc: 0.9569\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 357us/step - loss: 0.1184 - acc: 0.9595\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.0842 - acc: 0.9700\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.0551 - acc: 0.9791\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.0608 - acc: 0.9791\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.2426 - acc: 0.9191\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.0886 - acc: 0.9804\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.0298 - acc: 0.9909\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 0.0322 - acc: 0.9869\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.0758 - acc: 0.9791\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.0647 - acc: 0.9739\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.0831 - acc: 0.9778\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.2444 - acc: 0.9282\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.1743 - acc: 0.9347\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.0427 - acc: 0.9883\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 354us/step - loss: 0.0330 - acc: 0.9883\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.1209 - acc: 0.9648\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 0.0475 - acc: 0.9883\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 0.0338 - acc: 0.9869\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.0684 - acc: 0.9830\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.0227 - acc: 0.9909\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.0284 - acc: 0.9909\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.0670 - acc: 0.9739\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 357us/step - loss: 0.1776 - acc: 0.9530\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 360us/step - loss: 0.0908 - acc: 0.9634\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.0488 - acc: 0.9804\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.0577 - acc: 0.9778\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.0814 - acc: 0.9752\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.0361 - acc: 0.9909\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.0789 - acc: 0.9739\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 358us/step - loss: 0.0641 - acc: 0.9739\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.1626 - acc: 0.9569\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.0721 - acc: 0.9674\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.0223 - acc: 0.9948\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.0633 - acc: 0.9739\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.2162 - acc: 0.9321\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.1460 - acc: 0.9543\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 351us/step - loss: 0.0772 - acc: 0.9713\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.0391 - acc: 0.9896\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.1865 - acc: 0.9321\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.2235 - acc: 0.9204\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.1767 - acc: 0.9386\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.0566 - acc: 0.9869\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.0178 - acc: 0.9961\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.0326 - acc: 0.9896\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.0336 - acc: 0.9935\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.1140 - acc: 0.9739\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.2168 - acc: 0.9373\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.0686 - acc: 0.9804\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.0918 - acc: 0.9713\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 355us/step - loss: 0.0673 - acc: 0.9765\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 352us/step - loss: 0.0108 - acc: 0.9948\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.0055 - acc: 0.9987\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.0011 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 433us/step\n",
      "Test loss  2  :  0.12332403772355367\n",
      "Test accuracy 2  :  0.9791666666666666\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 729us/step - loss: 0.6547 - acc: 0.6488\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 352us/step - loss: 0.6435 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.6330 - acc: 0.6527\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.6208 - acc: 0.6567\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.6024 - acc: 0.6932\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 455us/step - loss: 0.6005 - acc: 0.6867\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.5529 - acc: 0.7376\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.5436 - acc: 0.7428\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.5156 - acc: 0.7546\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.4924 - acc: 0.7781\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.4590 - acc: 0.7950\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.4601 - acc: 0.7898\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.4383 - acc: 0.7950\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.4142 - acc: 0.8211\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.4243 - acc: 0.8068\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.3836 - acc: 0.8381\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 423us/step - loss: 0.3624 - acc: 0.8394\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.3722 - acc: 0.8264\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.3298 - acc: 0.8590\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.3018 - acc: 0.8577\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.3205 - acc: 0.8603\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.2874 - acc: 0.8930\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.2733 - acc: 0.8851\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.2180 - acc: 0.9021\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.2237 - acc: 0.9138\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.2153 - acc: 0.9151\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.2594 - acc: 0.8838\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2679 - acc: 0.8851\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.1554 - acc: 0.9373\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.2626 - acc: 0.9073\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.1802 - acc: 0.9413\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.1662 - acc: 0.9386\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 0.1453 - acc: 0.9426\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.1788 - acc: 0.9426\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.1196 - acc: 0.9595\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.2673 - acc: 0.9191\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.1298 - acc: 0.9517\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.0820 - acc: 0.9739\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.2274 - acc: 0.9138\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1404 - acc: 0.9452\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1985 - acc: 0.9373\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1047 - acc: 0.9634\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.0926 - acc: 0.9687\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.0575 - acc: 0.9830\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1581 - acc: 0.9478\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 360us/step - loss: 0.1708 - acc: 0.9530\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.1975 - acc: 0.9347\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.1075 - acc: 0.9648\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.1157 - acc: 0.9543\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.0706 - acc: 0.9778\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.1211 - acc: 0.9621\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 427us/step - loss: 0.0891 - acc: 0.9661\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1125 - acc: 0.9713\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 351us/step - loss: 0.0692 - acc: 0.9778\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.1940 - acc: 0.9295\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.0848 - acc: 0.9726\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.0288 - acc: 0.9883\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.0072 - acc: 0.9987\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 9.0185e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 6.0126e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 4.6936e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 3.9494e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 3.4276e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 2.9548e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 2.6901e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 438us/step - loss: 2.4217e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 2.1922e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 2.0520e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 1.9014e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 1.7745e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 1.6715e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 1.5740e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 1.4881e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.4275e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 1.3533e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 1.2889e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 1.2319e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 424us/step - loss: 1.1804e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 1.1364e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 1.0924e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 1.0447e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 1.0076e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 9.7395e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 9.3787e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 9.1144e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 8.7551e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 8.4920e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 418us/step - loss: 8.2286e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 7.9692e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 7.7672e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 7.5414e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 7.3386e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 7.1536e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 6.9691e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 6.7940e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 357us/step - loss: 6.6191e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 436us/step - loss: 6.4680e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 6.3011e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 6.1634e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 493us/step\n",
      "Test loss  3  :  0.06537970420564913\n",
      "Test accuracy 3  :  0.9791666666666666\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 775us/step - loss: 0.6531 - acc: 0.6540\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.6408 - acc: 0.6514\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.6237 - acc: 0.6488\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.6117 - acc: 0.6762\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.5895 - acc: 0.7023\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.5677 - acc: 0.7272\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 0.5259 - acc: 0.7572\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.5261 - acc: 0.7520\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 359us/step - loss: 0.4950 - acc: 0.7624\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.4774 - acc: 0.7833\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 435us/step - loss: 0.4484 - acc: 0.7937\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.4463 - acc: 0.7963\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.4283 - acc: 0.8042\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.4358 - acc: 0.8081\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.3756 - acc: 0.8407\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.3606 - acc: 0.8407\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.3404 - acc: 0.8512\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.3373 - acc: 0.8590\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.3093 - acc: 0.8773\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.3124 - acc: 0.8708\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.3341 - acc: 0.8708\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.2613 - acc: 0.8982\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.2405 - acc: 0.9073\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.2699 - acc: 0.8838\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.2120 - acc: 0.9178\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2823 - acc: 0.8864\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.1955 - acc: 0.9282\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 0.1766 - acc: 0.9373\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.1913 - acc: 0.9256\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.1672 - acc: 0.9295\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.1954 - acc: 0.9295\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.1599 - acc: 0.9413\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.1368 - acc: 0.9465\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 0.2195 - acc: 0.9178\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1383 - acc: 0.9360\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 0.1565 - acc: 0.9439\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.1073 - acc: 0.9634\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 430us/step - loss: 0.1982 - acc: 0.9256\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 0.1777 - acc: 0.9452\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.1130 - acc: 0.9569\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.0935 - acc: 0.9661\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.0968 - acc: 0.9661\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 0.2330 - acc: 0.9099\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 0.1626 - acc: 0.9360\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 427us/step - loss: 0.1611 - acc: 0.9373\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.1175 - acc: 0.9530\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.0456 - acc: 0.9830\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.1202 - acc: 0.9595\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.0925 - acc: 0.9661\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 0.0175 - acc: 0.9948\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 8.9418e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 418us/step - loss: 6.6158e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 5.1983e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 4.4148e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 3.8546e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 3.4090e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 3.0655e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 2.7816e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 2.5461e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 2.3528e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 2.1758e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 2.0344e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 1.8936e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 1.7885e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 1.6881e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.5925e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 1.5167e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 348us/step - loss: 1.4406e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 1.3752e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 1.3156e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 1.2636e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 1.2058e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 1.1614e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.1245e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 1.0753e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 1.0425e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 1.0082e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 9.7382e-05 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 9.4111e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 9.1362e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 8.8520e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 8.5960e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 8.3750e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 8.1220e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 7.9025e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 7.7357e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 7.5098e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 7.3261e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 7.1366e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 417us/step - loss: 6.9580e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 355us/step - loss: 6.8055e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 6.6368e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 6.4985e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 6.3628e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 440us/step - loss: 6.2326e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 6.0853e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 5.9552e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 5.8343e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 576us/step\n",
      "Test loss  4  :  0.05235447234978589\n",
      "Test accuracy 4  :  0.9895833333333334\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 905us/step - loss: 0.6543 - acc: 0.6488\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 0.6360 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.6407 - acc: 0.6319\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.6351 - acc: 0.6540\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 0.6143 - acc: 0.6775\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.5859 - acc: 0.6997\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.5892 - acc: 0.6880\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.5642 - acc: 0.7258\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 433us/step - loss: 0.5262 - acc: 0.7533\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.5267 - acc: 0.7598\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.4965 - acc: 0.7650\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.4539 - acc: 0.7963\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.4913 - acc: 0.7702\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.4228 - acc: 0.8225\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.4306 - acc: 0.8238\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.3988 - acc: 0.8290\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 431us/step - loss: 0.4141 - acc: 0.8264\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.4240 - acc: 0.8094\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 415us/step - loss: 0.3667 - acc: 0.8486\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.3577 - acc: 0.8420\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.3543 - acc: 0.8473\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.3134 - acc: 0.8603\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.3327 - acc: 0.8655\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.2716 - acc: 0.8786\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.2773 - acc: 0.8982\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.2453 - acc: 0.9073\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.2337 - acc: 0.8969\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.2264 - acc: 0.9086\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.1927 - acc: 0.9243\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.2396 - acc: 0.9034\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.2280 - acc: 0.8864\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2068 - acc: 0.9243\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.1726 - acc: 0.9282\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 423us/step - loss: 0.1531 - acc: 0.9465\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.2792 - acc: 0.9073\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.1289 - acc: 0.9530\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.2040 - acc: 0.9321\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.0797 - acc: 0.9687\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.2541 - acc: 0.9178\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 0.1224 - acc: 0.9491\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.1924 - acc: 0.9269\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.1377 - acc: 0.9504\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.1594 - acc: 0.9321\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.1423 - acc: 0.9530\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.1028 - acc: 0.9621\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.0867 - acc: 0.9713\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 423us/step - loss: 0.1019 - acc: 0.9726\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.1846 - acc: 0.9491\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.0580 - acc: 0.9765\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.0437 - acc: 0.9843\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.0503 - acc: 0.9817\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.1511 - acc: 0.9595\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1076 - acc: 0.9608\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.0193 - acc: 0.9935\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.1125 - acc: 0.9739\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.1538 - acc: 0.9426\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.0888 - acc: 0.9648\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.0600 - acc: 0.9830\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.0358 - acc: 0.9869\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 436us/step - loss: 0.0572 - acc: 0.9804\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 0.2860 - acc: 0.9151\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.0728 - acc: 0.9765\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.0924 - acc: 0.9661\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.0954 - acc: 0.9713\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 424us/step - loss: 0.1284 - acc: 0.9608\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.1134 - acc: 0.9569\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.0644 - acc: 0.9752\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.1422 - acc: 0.9595\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 0.0237 - acc: 0.9909\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 445us/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 427us/step - loss: 9.3314e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 441us/step - loss: 7.4953e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 6.2185e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 5.3214e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 4.6675e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 4.1055e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 3.6910e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 3.3485e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 3.0434e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 2.7835e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 2.5728e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 2.3989e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 2.2348e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 433us/step - loss: 2.0900e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 1.9602e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 436us/step - loss: 1.8516e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 447us/step - loss: 1.7676e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 429us/step - loss: 1.6565e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 1.5807e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 1.5113e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 1.4404e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 1.3766e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 422us/step - loss: 1.3151e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 1.2619e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 1.2163e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 1.1677e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.1279e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 1.0899e-04 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 666us/step\n",
      "Test loss  5  :  0.07771873283976068\n",
      "Test accuracy 5  :  0.9791666666666666\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 871us/step - loss: 0.6556 - acc: 0.6488\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.6423 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.6224 - acc: 0.6554\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.6147 - acc: 0.6710\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 0.5843 - acc: 0.7089\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.5627 - acc: 0.7115\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.5404 - acc: 0.7272\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 415us/step - loss: 0.5197 - acc: 0.7572\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 359us/step - loss: 0.5187 - acc: 0.7611\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.4688 - acc: 0.7859\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.4606 - acc: 0.7794\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.4614 - acc: 0.7859\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.4250 - acc: 0.8003\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 465us/step - loss: 0.3999 - acc: 0.8211\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.4061 - acc: 0.8277\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.3766 - acc: 0.8407\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.3552 - acc: 0.8381\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.3418 - acc: 0.8499\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 414us/step - loss: 0.3561 - acc: 0.8446\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 419us/step - loss: 0.3415 - acc: 0.8577\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 456us/step - loss: 0.3075 - acc: 0.8551\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 438us/step - loss: 0.2949 - acc: 0.8799\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.3114 - acc: 0.8577\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 429us/step - loss: 0.2561 - acc: 0.8930\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.3190 - acc: 0.8642\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.2737 - acc: 0.8721\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.2438 - acc: 0.9047\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.2497 - acc: 0.8903\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.2110 - acc: 0.9060\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.2429 - acc: 0.9047\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.2459 - acc: 0.8969\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 0.2729 - acc: 0.8969\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.1996 - acc: 0.9178\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1708 - acc: 0.9334\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.1581 - acc: 0.9399\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 0.2015 - acc: 0.9204\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.1980 - acc: 0.9204\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.1419 - acc: 0.9491\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1496 - acc: 0.9465\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.1899 - acc: 0.9347\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1479 - acc: 0.9452\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.1365 - acc: 0.9530\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.1235 - acc: 0.9582\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.1078 - acc: 0.9661\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.2130 - acc: 0.9191\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.1755 - acc: 0.9439\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.1609 - acc: 0.9439\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.0842 - acc: 0.9739\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.1067 - acc: 0.9648\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.2065 - acc: 0.9308\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.1387 - acc: 0.9582\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.0899 - acc: 0.9687\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.0457 - acc: 0.9817\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.0786 - acc: 0.9739\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 0.0655 - acc: 0.9765\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.0811 - acc: 0.9726\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.1700 - acc: 0.9386\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.0622 - acc: 0.9791\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.0936 - acc: 0.9791\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.0140 - acc: 0.9974\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 0.0061 - acc: 0.9987\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 8.4384e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 6.9479e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 4.6738e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 3.9831e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 3.4683e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 3.1028e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 2.8054e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 2.5847e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 351us/step - loss: 2.3739e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 2.2132e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 2.0621e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 1.9306e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 1.8183e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 1.7168e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 1.6258e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 1.5427e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 1.4671e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 1.4075e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 1.3477e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 1.2916e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 418us/step - loss: 1.2385e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 429us/step - loss: 1.1953e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 444us/step - loss: 1.1514e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.1068e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 1.0699e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 415us/step - loss: 1.0371e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 9.9992e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 9.7132e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 435us/step - loss: 9.4180e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 414us/step - loss: 9.1545e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 442us/step - loss: 8.8882e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 436us/step - loss: 8.6161e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 8.3985e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 8.1735e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 7.9695e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 7.7751e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 7.5499e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 690us/step\n",
      "Test loss  6  :  0.04131505320159098\n",
      "Test accuracy 6  :  0.984375\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 905us/step - loss: 0.6491 - acc: 0.6540\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.6472 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.6288 - acc: 0.6619\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 0.6090 - acc: 0.6867\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.5879 - acc: 0.7076\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.5783 - acc: 0.6971\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.5499 - acc: 0.7376\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 358us/step - loss: 0.5164 - acc: 0.7572\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.5139 - acc: 0.7598\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.4823 - acc: 0.7846\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.4825 - acc: 0.7637\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.4386 - acc: 0.7990\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 356us/step - loss: 0.4293 - acc: 0.8003\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.4322 - acc: 0.8029\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 0.4191 - acc: 0.8290\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.4077 - acc: 0.8198\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 0.3771 - acc: 0.8251\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.3484 - acc: 0.8407\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 0.3537 - acc: 0.8473\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 0.3324 - acc: 0.8525\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.3403 - acc: 0.8538\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.3160 - acc: 0.8603\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.3037 - acc: 0.8655\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.2764 - acc: 0.8734\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 356us/step - loss: 0.2955 - acc: 0.8695\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.2592 - acc: 0.8969\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2606 - acc: 0.8851\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 440us/step - loss: 0.2028 - acc: 0.9164\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.1656 - acc: 0.9256\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.2134 - acc: 0.9191\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.2198 - acc: 0.8930\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 355us/step - loss: 0.2211 - acc: 0.9112\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.1483 - acc: 0.9491\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.1691 - acc: 0.9308\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.1656 - acc: 0.9386\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.2185 - acc: 0.9138\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.1258 - acc: 0.9439\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 0.1760 - acc: 0.9360\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.1685 - acc: 0.9426\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.0994 - acc: 0.9634\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 0.1209 - acc: 0.9452\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.1523 - acc: 0.9504\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.0855 - acc: 0.9778\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.2058 - acc: 0.9321\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.2373 - acc: 0.9360\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.1887 - acc: 0.9347\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.1451 - acc: 0.9426\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 359us/step - loss: 0.1571 - acc: 0.9478\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.0874 - acc: 0.9713\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 0.0560 - acc: 0.9817\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.0555 - acc: 0.9883\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.0473 - acc: 0.9883\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.1338 - acc: 0.9569\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 358us/step - loss: 0.1751 - acc: 0.9439\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.1411 - acc: 0.9530\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 409us/step - loss: 0.0875 - acc: 0.9713\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.3353 - acc: 0.8786\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.1082 - acc: 0.9634\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 452us/step - loss: 0.0502 - acc: 0.9804\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.0593 - acc: 0.9804\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.0266 - acc: 0.9922\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 7.2704e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 5.4565e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 4.5702e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 3.8835e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 3.3567e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 353us/step - loss: 3.0352e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 2.7379e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 2.4785e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 2.2907e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 2.1251e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 1.9855e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 1.8613e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 1.7445e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 1.6427e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 341us/step - loss: 1.5628e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 1.4849e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 1.4132e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 1.3468e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 1.2881e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.2331e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 1.1908e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 1.1423e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 1.1001e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 1.0573e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 361us/step - loss: 1.0234e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 9.9018e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 9.5066e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 400us/step - loss: 9.2331e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 8.9824e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 8.6903e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 8.4337e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 8.2071e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 7.9627e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 7.7279e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 7.5107e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 7.3459e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 822us/step\n",
      "Test loss  7  :  0.045643457296440225\n",
      "Test accuracy 7  :  0.984375\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 0.6523 - acc: 0.6527\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 0.6421 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.6316 - acc: 0.6593\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.6067 - acc: 0.6880\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.6005 - acc: 0.6984\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.5700 - acc: 0.7285\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.5518 - acc: 0.7363\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 429us/step - loss: 0.5113 - acc: 0.7520\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 411us/step - loss: 0.4840 - acc: 0.7715\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.5007 - acc: 0.7585\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.4406 - acc: 0.8107\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.4319 - acc: 0.8068\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.4206 - acc: 0.8277\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.4160 - acc: 0.8133\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 0.4013 - acc: 0.8238\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.3942 - acc: 0.8198\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.3835 - acc: 0.8238\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 445us/step - loss: 0.3401 - acc: 0.8486\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.3182 - acc: 0.8551\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.3261 - acc: 0.8616\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 0.3267 - acc: 0.8525\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.2755 - acc: 0.8851\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2848 - acc: 0.8760\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.2558 - acc: 0.9021\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.2547 - acc: 0.8799\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2411 - acc: 0.8930\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.2068 - acc: 0.9164\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 434us/step - loss: 0.1608 - acc: 0.9399\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.1526 - acc: 0.9295\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1868 - acc: 0.9282\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.1650 - acc: 0.9465\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.1565 - acc: 0.9413\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.1599 - acc: 0.9399\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.1057 - acc: 0.9634\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 422us/step - loss: 0.2002 - acc: 0.9217\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.0884 - acc: 0.9687\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 430us/step - loss: 0.2611 - acc: 0.9086\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1360 - acc: 0.9452\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.1255 - acc: 0.9478\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.1235 - acc: 0.9608\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 367us/step - loss: 0.1422 - acc: 0.9530\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 0.0831 - acc: 0.9674\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1146 - acc: 0.9556\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 0.0945 - acc: 0.9674\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.1959 - acc: 0.9373\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.0612 - acc: 0.9791\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.2158 - acc: 0.9530\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 0.1754 - acc: 0.9543\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.0716 - acc: 0.9765\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 360us/step - loss: 0.0652 - acc: 0.9765\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.1233 - acc: 0.9608\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.1646 - acc: 0.9465\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 444us/step - loss: 0.0483 - acc: 0.9804\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 0.0921 - acc: 0.9674\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.0948 - acc: 0.9634\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.0984 - acc: 0.9595\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.1796 - acc: 0.9478\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.0831 - acc: 0.9804\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 413us/step - loss: 0.1107 - acc: 0.9608\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 380us/step - loss: 0.0427 - acc: 0.9856\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.1144 - acc: 0.9752\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.1211 - acc: 0.9608\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 0.0529 - acc: 0.9804\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 0.0213 - acc: 0.9948\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 0.0083 - acc: 0.9987\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 0.0047 - acc: 0.9974\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.0037 - acc: 0.9987\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 4.3534e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 395us/step - loss: 3.1722e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 451us/step - loss: 2.5064e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 405us/step - loss: 2.1249e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 1.8798e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 1.6943e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 1.5445e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 1.4421e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 1.3272e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 1.2464e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 412us/step - loss: 1.1725e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 410us/step - loss: 1.1033e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 404us/step - loss: 1.0533e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 9.9675e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 9.5597e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 9.0685e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 375us/step - loss: 8.7303e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 8.3400e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 8.0698e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 357us/step - loss: 7.7847e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 394us/step - loss: 7.5104e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 7.2431e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 467us/step - loss: 7.0298e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 422us/step - loss: 6.7933e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 6.6221e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 425us/step - loss: 6.4296e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 6.2521e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 386us/step - loss: 6.0715e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 5.8949e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 5.7503e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 360us/step - loss: 5.5980e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 5.4697e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 5.3465e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 883us/step\n",
      "Test loss  8  :  0.15715670474795237\n",
      "Test accuracy 8  :  0.984375\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 0.6496 - acc: 0.6540\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 0.6373 - acc: 0.6540\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.6268 - acc: 0.6619\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.6040 - acc: 0.6775\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 0s 393us/step - loss: 0.5927 - acc: 0.6828\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.5784 - acc: 0.7193\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.5409 - acc: 0.7520\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.5318 - acc: 0.7507\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 0.5607 - acc: 0.7180\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 0.4953 - acc: 0.7689\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.4829 - acc: 0.7755\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 0s 430us/step - loss: 0.4850 - acc: 0.7559\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.4838 - acc: 0.7781\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.4427 - acc: 0.7977\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 0.4531 - acc: 0.7846\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.4142 - acc: 0.8146\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 0.4021 - acc: 0.8277\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 0s 407us/step - loss: 0.3825 - acc: 0.8251\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.3557 - acc: 0.8394\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.3780 - acc: 0.8303\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.3577 - acc: 0.8433\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.3022 - acc: 0.8825\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 0.3296 - acc: 0.8564\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.3269 - acc: 0.8642\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.2765 - acc: 0.8851\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 0.2812 - acc: 0.8851\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.2681 - acc: 0.8838\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 0s 390us/step - loss: 0.3054 - acc: 0.8695\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.3041 - acc: 0.8668\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 0s 385us/step - loss: 0.2671 - acc: 0.8930\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 0s 402us/step - loss: 0.3355 - acc: 0.8629\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.2288 - acc: 0.9073\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 0s 366us/step - loss: 0.2251 - acc: 0.9164\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.2034 - acc: 0.9164\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 0.2933 - acc: 0.8812\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.1477 - acc: 0.9373\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.2067 - acc: 0.9191\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 0s 401us/step - loss: 0.1562 - acc: 0.9347\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 0s 383us/step - loss: 0.1201 - acc: 0.9569\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.1644 - acc: 0.9413\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 0s 427us/step - loss: 0.2303 - acc: 0.9099\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.1970 - acc: 0.9360\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 0s 388us/step - loss: 0.1634 - acc: 0.9426\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 0s 428us/step - loss: 0.1247 - acc: 0.9556\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 0s 356us/step - loss: 0.1316 - acc: 0.9504\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 0.1065 - acc: 0.9700\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.1475 - acc: 0.9491\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.1728 - acc: 0.9452\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 0s 382us/step - loss: 0.0588 - acc: 0.9830\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 0.1533 - acc: 0.9608\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 0s 416us/step - loss: 0.0955 - acc: 0.9543\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 0s 414us/step - loss: 0.1253 - acc: 0.9582\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 0s 406us/step - loss: 0.1106 - acc: 0.9595\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 0s 414us/step - loss: 0.1667 - acc: 0.9360\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 0.0805 - acc: 0.9687\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 0s 368us/step - loss: 0.0644 - acc: 0.9765\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 0.1971 - acc: 0.9399\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 0s 399us/step - loss: 0.2270 - acc: 0.9151\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 0s 391us/step - loss: 0.1088 - acc: 0.9687\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 0.0953 - acc: 0.9595\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.0630 - acc: 0.9739\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 0s 365us/step - loss: 0.0561 - acc: 0.9856\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 0s 371us/step - loss: 0.0849 - acc: 0.9739\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 0s 362us/step - loss: 0.1241 - acc: 0.9504\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 0s 421us/step - loss: 0.0362 - acc: 0.9896\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 0s 364us/step - loss: 0.0360 - acc: 0.9909\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 0.0385 - acc: 0.9869\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 0s 392us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 0s 376us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 8.3129e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 6.6583e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 5.4176e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 4.6408e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 4.0012e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 0s 435us/step - loss: 3.5541e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 3.1957e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 2.9381e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 2.6630e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 0s 397us/step - loss: 2.4424e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 2.2762e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 0s 398us/step - loss: 2.1260e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 0s 384us/step - loss: 1.9929e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 0s 377us/step - loss: 1.8757e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 0s 363us/step - loss: 1.7653e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 0s 389us/step - loss: 1.6880e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 1.5871e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 0s 372us/step - loss: 1.5013e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 0s 370us/step - loss: 1.4362e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 0s 381us/step - loss: 1.3655e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 0s 373us/step - loss: 1.3056e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 0s 369us/step - loss: 1.2517e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 0s 396us/step - loss: 1.2047e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 0s 408us/step - loss: 1.1593e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 0s 379us/step - loss: 1.1151e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 0s 403us/step - loss: 1.0704e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 0s 436us/step - loss: 1.0374e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 0s 387us/step - loss: 9.9920e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 0s 374us/step - loss: 9.6512e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 0s 420us/step - loss: 9.3638e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 0s 378us/step - loss: 9.0801e-05 - acc: 1.0000\n",
      "192/192 [==============================] - 0s 900us/step\n",
      "Test loss  9  :  0.1059896455311294\n",
      "Test accuracy 9  :  0.984375\n",
      "Max accuracy rate : 0.9895833333333334\n",
      "Min accuracy rate : 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(10):\n",
    "  nnet = Sequential()\n",
    "  nnet.add(Dense(units=100, kernel_initializer='uniform', activation='relu', input_dim=9, use_bias=True))\n",
    "  nnet.add(Dense(units=100, kernel_initializer='uniform', activation='relu', use_bias=True))\n",
    "  nnet.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid', use_bias=True))\n",
    "  nnet.compile(optimizer=optimizers.SGD(lr=0.06, decay=1e-6, momentum=0.9, nesterov=True) , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  nnet.fit(X_train, y_train, batch_size=10, epochs=100, verbose=1)\n",
    "\n",
    "  score = nnet.evaluate(X_test, y_test, verbose=1)\n",
    "  print('Test loss ', i, ' : ', score[0])\n",
    "  print('Test accuracy', i, ' : ', score[1])\n",
    "  scores.append(score[1])\n",
    "print('Max accuracy rate :', np.array(scores).max())\n",
    "print('Min accuracy rate :', np.array(scores).min())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TicTacToe_Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
